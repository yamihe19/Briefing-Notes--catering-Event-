{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yamihe19/Briefing-Notes-Catering-Event-/blob/main/Code_Project_ResearchArticle_ipynbipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc3uSVr4YE0l"
      },
      "source": [
        "#PROJECT: Linear discriminant analysis of phenotypic data for classifying autism spectrum disorder by diagnosis and sex\n",
        "\n",
        "### Group Members:\n",
        "- Mary Alexandra Garcia 100391387\n",
        "- Yamileth Hercules 100385215"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQW28UpHYrmi"
      },
      "source": [
        "## a. Purpose\n",
        "\n",
        "Recreate the results of the article using LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UcWkIKsY6qs"
      },
      "source": [
        "__b. Objectives:__<br>\n",
        "    \n",
        "1. EDA (15 points): this will include a description of the data, inclusion and exclusion criteria to filter the data for your classification tasks.\n",
        "2. Perform LDA analysis (15 points).\n",
        "3. Perform another classification analysis (15 points).\n",
        "4. Conclusion on the performance of LDA in comparison to the technique that you use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-OhdJHoYIbS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWGvtsdraPaK"
      },
      "source": [
        "### Reading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bR_4FrRbkAZ"
      },
      "source": [
        "In this part we evaluated the datasets of the kaggle folder and we found that the important one is 'pheno_train.csv' as the article mentioned that they did all the preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "i_e_5lDY8hpc",
        "outputId": "d23183ce-3c08-42c8-f66e-931a0804e451"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-541f34e5-fe5c-48db-b7d3-98d5054d1ac0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>X</th>\n",
              "      <th>subject</th>\n",
              "      <th>SITE_ID</th>\n",
              "      <th>FILE_ID</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>SEX</th>\n",
              "      <th>HANDEDNESS_CATEGORY</th>\n",
              "      <th>HANDEDNESS_SCORES</th>\n",
              "      <th>FIQ</th>\n",
              "      <th>VIQ</th>\n",
              "      <th>PIQ</th>\n",
              "      <th>FIQ_TEST_TYPE</th>\n",
              "      <th>VIQ_TEST_TYPE</th>\n",
              "      <th>PIQ_TEST_TYPE</th>\n",
              "      <th>ADI_R_SOCIAL_TOTAL_A</th>\n",
              "      <th>ADI_R_VERBAL_TOTAL_BV</th>\n",
              "      <th>ADI_RRB_TOTAL_C</th>\n",
              "      <th>ADI_R_ONSET_TOTAL_D</th>\n",
              "      <th>ADI_R_RSRCH_RELIABLE</th>\n",
              "      <th>ADOS_MODULE</th>\n",
              "      <th>ADOS_TOTAL</th>\n",
              "      <th>ADOS_COMM</th>\n",
              "      <th>ADOS_SOCIAL</th>\n",
              "      <th>ADOS_STEREO_BEHAV</th>\n",
              "      <th>ADOS_RSRCH_RELIABLE</th>\n",
              "      <th>ADOS_GOTHAM_SOCAFFECT</th>\n",
              "      <th>ADOS_GOTHAM_RRB</th>\n",
              "      <th>ADOS_GOTHAM_TOTAL</th>\n",
              "      <th>ADOS_GOTHAM_SEVERITY</th>\n",
              "      <th>SRS_VERSION</th>\n",
              "      <th>SRS_RAW_TOTAL</th>\n",
              "      <th>SRS_AWARENESS</th>\n",
              "      <th>SRS_COGNITION</th>\n",
              "      <th>SRS_COMMUNICATION</th>\n",
              "      <th>SRS_MOTIVATION</th>\n",
              "      <th>SRS_MANNERISMS</th>\n",
              "      <th>SCQ_TOTAL</th>\n",
              "      <th>AQ_TOTAL</th>\n",
              "      <th>COMORBIDITY</th>\n",
              "      <th>CURRENT_MED_STATUS</th>\n",
              "      <th>MEDICATION_NAME</th>\n",
              "      <th>OFF_STIMULANTS_AT_SCAN</th>\n",
              "      <th>VINELAND_RECEPTIVE_V_SCALED</th>\n",
              "      <th>VINELAND_EXPRESSIVE_V_SCALED</th>\n",
              "      <th>VINELAND_WRITTEN_V_SCALED</th>\n",
              "      <th>VINELAND_COMMUNICATION_STANDARD</th>\n",
              "      <th>VINELAND_PERSONAL_V_SCALED</th>\n",
              "      <th>VINELAND_DOMESTIC_V_SCALED</th>\n",
              "      <th>VINELAND_COMMUNITY_V_SCALED</th>\n",
              "      <th>VINELAND_DAILYLVNG_STANDARD</th>\n",
              "      <th>VINELAND_INTERPERSONAL_V_SCALED</th>\n",
              "      <th>VINELAND_PLAY_V_SCALED</th>\n",
              "      <th>VINELAND_COPING_V_SCALED</th>\n",
              "      <th>VINELAND_SOCIAL_STANDARD</th>\n",
              "      <th>VINELAND_SUM_SCORES</th>\n",
              "      <th>VINELAND_ABC_STANDARD</th>\n",
              "      <th>VINELAND_INFORMANT</th>\n",
              "      <th>WISC_IV_VCI</th>\n",
              "      <th>WISC_IV_PRI</th>\n",
              "      <th>WISC_IV_WMI</th>\n",
              "      <th>WISC_IV_PSI</th>\n",
              "      <th>WISC_IV_SIM_SCALED</th>\n",
              "      <th>WISC_IV_VOCAB_SCALED</th>\n",
              "      <th>WISC_IV_INFO_SCALED</th>\n",
              "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
              "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
              "      <th>WISC_IV_MATRIX_SCALED</th>\n",
              "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
              "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
              "      <th>WISC_IV_CODING_SCALED</th>\n",
              "      <th>WISC_IV_SYM_SCALED</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>AGE_AT_MPRAGE</th>\n",
              "      <th>BMI</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>qc_rater_1</th>\n",
              "      <th>qc_notes_rater_1</th>\n",
              "      <th>qc_anat_rater_2</th>\n",
              "      <th>qc_anat_notes_rater_2</th>\n",
              "      <th>qc_func_rater_2</th>\n",
              "      <th>qc_func_notes_rater_2</th>\n",
              "      <th>qc_anat_rater_3</th>\n",
              "      <th>qc_anat_notes_rater_3</th>\n",
              "      <th>qc_func_rater_3</th>\n",
              "      <th>qc_func_notes_rater_3</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>814</td>\n",
              "      <td>51131</td>\n",
              "      <td>815</td>\n",
              "      <td>51131</td>\n",
              "      <td>NYU</td>\n",
              "      <td>NYU_0051131</td>\n",
              "      <td>2</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.00</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162</td>\n",
              "      <td>50237</td>\n",
              "      <td>163</td>\n",
              "      <td>50237</td>\n",
              "      <td>TRINITY</td>\n",
              "      <td>Trinity_0050237</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>118.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>863</td>\n",
              "      <td>51185</td>\n",
              "      <td>864</td>\n",
              "      <td>51185</td>\n",
              "      <td>STANFORD</td>\n",
              "      <td>Stanford_0051185</td>\n",
              "      <td>2</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>119.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>69.0</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>maybe</td>\n",
              "      <td>skull-striping fail;</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>668</td>\n",
              "      <td>50978</td>\n",
              "      <td>669</td>\n",
              "      <td>50978</td>\n",
              "      <td>NYU</td>\n",
              "      <td>NYU_0050978</td>\n",
              "      <td>1</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mood Disorder NOS</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.71</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>508</td>\n",
              "      <td>50653</td>\n",
              "      <td>509</td>\n",
              "      <td>50653</td>\n",
              "      <td>CMU</td>\n",
              "      <td>CMU_a_0050653</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>134.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>WISC</td>\n",
              "      <td>WISC</td>\n",
              "      <td>WISC</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>84.0</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>fail</td>\n",
              "      <td>ventral edge is cropped</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>ic-frontal-temporal-cerebellum</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-541f34e5-fe5c-48db-b7d3-98d5054d1ac0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-541f34e5-fe5c-48db-b7d3-98d5054d1ac0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-541f34e5-fe5c-48db-b7d3-98d5054d1ac0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  SUB_ID    X  subject   SITE_ID           FILE_ID  DX_GROUP  \\\n",
              "0         814   51131  815    51131       NYU       NYU_0051131         2   \n",
              "1         162   50237  163    50237   TRINITY   Trinity_0050237         1   \n",
              "2         863   51185  864    51185  STANFORD  Stanford_0051185         2   \n",
              "3         668   50978  669    50978       NYU       NYU_0050978         1   \n",
              "4         508   50653  509    50653       CMU     CMU_a_0050653         1   \n",
              "\n",
              "   AGE_AT_SCAN  SEX HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ    VIQ  \\\n",
              "0      19.7300    1                 NaN               68.0  119.0  112.0   \n",
              "1      21.4200    1                   R                NaN  118.0  109.0   \n",
              "2       8.2464    1                   R                NaN  119.0  107.0   \n",
              "3       9.5800    1                 NaN               44.0  142.0  126.0   \n",
              "4      30.0000    1                   R                NaN  134.0  131.0   \n",
              "\n",
              "     PIQ FIQ_TEST_TYPE VIQ_TEST_TYPE PIQ_TEST_TYPE  ADI_R_SOCIAL_TOTAL_A  \\\n",
              "0  123.0          WASI          WASI          WASI                   NaN   \n",
              "1  116.0          WASI           NaN           NaN                  20.0   \n",
              "2  129.0          WASI          WASI          WASI                   NaN   \n",
              "3  149.0          WASI          WASI          WASI                  16.0   \n",
              "4  129.0          WISC          WISC          WISC                  20.0   \n",
              "\n",
              "   ADI_R_VERBAL_TOTAL_BV  ADI_RRB_TOTAL_C  ADI_R_ONSET_TOTAL_D  \\\n",
              "0                    NaN              NaN                  NaN   \n",
              "1                   18.0              5.0                  5.0   \n",
              "2                    NaN              NaN                  NaN   \n",
              "3                   17.0              5.0                  3.0   \n",
              "4                   13.0              3.0                  1.0   \n",
              "\n",
              "   ADI_R_RSRCH_RELIABLE  ADOS_MODULE  ADOS_TOTAL  ADOS_COMM  ADOS_SOCIAL  \\\n",
              "0                   NaN          NaN         NaN        NaN          NaN   \n",
              "1                   1.0          4.0        17.0        NaN          NaN   \n",
              "2                   NaN          NaN         NaN        NaN          NaN   \n",
              "3                   1.0          3.0         7.0        0.0          7.0   \n",
              "4                   1.0          4.0        18.0        5.0         13.0   \n",
              "\n",
              "   ADOS_STEREO_BEHAV  ADOS_RSRCH_RELIABLE  ADOS_GOTHAM_SOCAFFECT  \\\n",
              "0                NaN                  NaN                    NaN   \n",
              "1                NaN                  NaN                    NaN   \n",
              "2                NaN                  NaN                    NaN   \n",
              "3                3.0                  1.0                    6.0   \n",
              "4                3.0                  1.0                    NaN   \n",
              "\n",
              "   ADOS_GOTHAM_RRB  ADOS_GOTHAM_TOTAL  ADOS_GOTHAM_SEVERITY  SRS_VERSION  \\\n",
              "0              NaN                NaN                   NaN      -9999.0   \n",
              "1              NaN                NaN                   NaN          NaN   \n",
              "2              NaN                NaN                   NaN          NaN   \n",
              "3              4.0               10.0                   6.0          1.0   \n",
              "4              NaN                NaN                   NaN          NaN   \n",
              "\n",
              "   SRS_RAW_TOTAL  SRS_AWARENESS  SRS_COGNITION  SRS_COMMUNICATION  \\\n",
              "0        -9999.0            NaN            NaN                NaN   \n",
              "1            NaN            NaN            NaN                NaN   \n",
              "2            NaN            NaN            NaN                NaN   \n",
              "3           92.0            NaN            NaN                NaN   \n",
              "4            NaN            NaN            NaN                NaN   \n",
              "\n",
              "   SRS_MOTIVATION  SRS_MANNERISMS  SCQ_TOTAL  AQ_TOTAL        COMORBIDITY  \\\n",
              "0             NaN             NaN        NaN       NaN                NaN   \n",
              "1             NaN             NaN        NaN       NaN                NaN   \n",
              "2             NaN             NaN        NaN       NaN                NaN   \n",
              "3             NaN             NaN       15.0       NaN  Mood Disorder NOS   \n",
              "4             NaN             NaN        NaN       NaN                NaN   \n",
              "\n",
              "  CURRENT_MED_STATUS MEDICATION_NAME  OFF_STIMULANTS_AT_SCAN  \\\n",
              "0                  0             NaN                     NaN   \n",
              "1                  0             NaN                     NaN   \n",
              "2                NaN             NaN                     NaN   \n",
              "3                  0             NaN                     NaN   \n",
              "4                  0             NaN                 -9999.0   \n",
              "\n",
              "   VINELAND_RECEPTIVE_V_SCALED  VINELAND_EXPRESSIVE_V_SCALED  \\\n",
              "0                      -9999.0                       -9999.0   \n",
              "1                          NaN                           NaN   \n",
              "2                          NaN                           NaN   \n",
              "3                         13.0                          12.0   \n",
              "4                          NaN                           NaN   \n",
              "\n",
              "   VINELAND_WRITTEN_V_SCALED  VINELAND_COMMUNICATION_STANDARD  \\\n",
              "0                    -9999.0                          -9999.0   \n",
              "1                        NaN                              NaN   \n",
              "2                        NaN                              NaN   \n",
              "3                       16.0                             92.0   \n",
              "4                        NaN                              NaN   \n",
              "\n",
              "   VINELAND_PERSONAL_V_SCALED  VINELAND_DOMESTIC_V_SCALED  \\\n",
              "0                     -9999.0                     -9999.0   \n",
              "1                         NaN                         NaN   \n",
              "2                         NaN                         NaN   \n",
              "3                        17.0                        12.0   \n",
              "4                         NaN                         NaN   \n",
              "\n",
              "   VINELAND_COMMUNITY_V_SCALED  VINELAND_DAILYLVNG_STANDARD  \\\n",
              "0                      -9999.0                      -9999.0   \n",
              "1                          NaN                          NaN   \n",
              "2                          NaN                          NaN   \n",
              "3                         14.0                         95.0   \n",
              "4                          NaN                          NaN   \n",
              "\n",
              "   VINELAND_INTERPERSONAL_V_SCALED  VINELAND_PLAY_V_SCALED  \\\n",
              "0                          -9999.0                 -9999.0   \n",
              "1                              NaN                     NaN   \n",
              "2                              NaN                     NaN   \n",
              "3                              9.0                    13.0   \n",
              "4                              NaN                     NaN   \n",
              "\n",
              "   VINELAND_COPING_V_SCALED  VINELAND_SOCIAL_STANDARD  VINELAND_SUM_SCORES  \\\n",
              "0                   -9999.0                   -9999.0              -9999.0   \n",
              "1                       NaN                       NaN                  NaN   \n",
              "2                       NaN                       NaN                  NaN   \n",
              "3                      13.0                      82.0                269.0   \n",
              "4                       NaN                       NaN                  NaN   \n",
              "\n",
              "   VINELAND_ABC_STANDARD  VINELAND_INFORMANT  WISC_IV_VCI  WISC_IV_PRI  \\\n",
              "0                -9999.0             -9999.0          NaN          NaN   \n",
              "1                    NaN                 NaN          NaN          NaN   \n",
              "2                    NaN                 NaN          NaN          NaN   \n",
              "3                   88.0                 1.0          NaN          NaN   \n",
              "4                    NaN                 NaN          NaN          NaN   \n",
              "\n",
              "   WISC_IV_WMI  WISC_IV_PSI  WISC_IV_SIM_SCALED  WISC_IV_VOCAB_SCALED  \\\n",
              "0          NaN          NaN                 NaN                   NaN   \n",
              "1          NaN          NaN                 NaN                   NaN   \n",
              "2          NaN          NaN                 NaN                   NaN   \n",
              "3          NaN          NaN                 NaN                   NaN   \n",
              "4          NaN          NaN                 NaN                   NaN   \n",
              "\n",
              "   WISC_IV_INFO_SCALED  WISC_IV_BLK_DSN_SCALED  WISC_IV_PIC_CON_SCALED  \\\n",
              "0                  NaN                     NaN                     NaN   \n",
              "1                  NaN                     NaN                     NaN   \n",
              "2                  NaN                     NaN                     NaN   \n",
              "3                  NaN                     NaN                     NaN   \n",
              "4                  NaN                     NaN                     NaN   \n",
              "\n",
              "   WISC_IV_MATRIX_SCALED  WISC_IV_DIGIT_SPAN_SCALED  WISC_IV_LET_NUM_SCALED  \\\n",
              "0                    NaN                        NaN                     NaN   \n",
              "1                    NaN                        NaN                     NaN   \n",
              "2                    NaN                        NaN                     NaN   \n",
              "3                    NaN                        NaN                     NaN   \n",
              "4                    NaN                        NaN                     NaN   \n",
              "\n",
              "   WISC_IV_CODING_SCALED  WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  \\\n",
              "0                    NaN                 NaN                   1   \n",
              "1                    NaN                 NaN                   2   \n",
              "2                    NaN                 NaN                   2   \n",
              "3                    NaN                 NaN                   1   \n",
              "4                    NaN                 NaN                   2   \n",
              "\n",
              "   AGE_AT_MPRAGE      BMI   anat_cnr   anat_efc  anat_fber  anat_fwhm  \\\n",
              "0            NaN -9999.00  10.674176   0.616051  89.045514   3.509732   \n",
              "1            NaN      NaN   7.004004   1.674990  11.113986   4.425869   \n",
              "2            NaN      NaN   9.180373  14.838937   0.029120   2.824676   \n",
              "3            NaN    13.71   9.087565   0.517920  78.004528   3.220905   \n",
              "4            NaN      NaN  26.045369   4.167438  32.931736   3.423460   \n",
              "\n",
              "   anat_qi1   anat_snr  func_efc   func_fber  func_fwhm  func_dvars  \\\n",
              "0  0.067764  12.866070  0.534295   78.296410   1.765660    1.018414   \n",
              "1  0.075520  10.833468  0.428382  137.815548   1.955725    1.064568   \n",
              "2  0.241977   9.159445  0.555808   59.038003   2.772167    1.302140   \n",
              "3  0.055056  10.456115  0.485962  142.036348   2.057008    0.938920   \n",
              "4  0.058810  68.951286  0.585246   88.589366   1.680437    1.156320   \n",
              "\n",
              "   func_outlier  func_quality  func_mean_fd  func_num_fd  func_perc_fd  \\\n",
              "0      0.006217      0.014129      0.032827          2.0      1.104972   \n",
              "1      0.002349      0.008713      0.078301          7.0      4.635762   \n",
              "2      0.007001      0.007197      0.181608         69.0     28.630705   \n",
              "3      0.006253      0.011202      0.030118          1.0      0.552486   \n",
              "4      0.001147      0.007730      0.187709         84.0     34.854772   \n",
              "\n",
              "   func_gsr qc_rater_1         qc_notes_rater_1 qc_anat_rater_2  \\\n",
              "0 -0.001329         OK                      NaN              OK   \n",
              "1  0.010631         OK                      NaN              OK   \n",
              "2  0.036467         OK                      NaN           maybe   \n",
              "3 -0.010039         OK                      NaN              OK   \n",
              "4  0.079297       fail  ventral edge is cropped              OK   \n",
              "\n",
              "  qc_anat_notes_rater_2 qc_func_rater_2           qc_func_notes_rater_2  \\\n",
              "0                   NaN              OK                             NaN   \n",
              "1                   NaN              OK                             NaN   \n",
              "2  skull-striping fail;              OK                             NaN   \n",
              "3                   NaN              OK                             NaN   \n",
              "4                   NaN            fail  ic-frontal-temporal-cerebellum   \n",
              "\n",
              "  qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3 qc_func_notes_rater_3  \\\n",
              "0              OK                   NaN              OK                   NaN   \n",
              "1              OK                   NaN              OK                   NaN   \n",
              "2              OK                   NaN              OK                   NaN   \n",
              "3              OK                   NaN              OK                   NaN   \n",
              "4              OK                   NaN              OK                   NaN   \n",
              "\n",
              "   SUB_IN_SMP  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           0  \n",
              "4           0  "
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df= pd.read_csv('pheno_train.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IYpTS1RapDz"
      },
      "source": [
        "## 1. EDA:this will include a description of the data, inclusion and exclusion criteria to filter the data for your classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHsmbixKRu6r",
        "outputId": "272bdec9-ff83-483c-c625-2bbfb32e3430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 931 entries, 0 to 930\n",
            "Columns: 104 entries, Unnamed: 0 to SUB_IN_SMP\n",
            "dtypes: float64(77), int64(8), object(19)\n",
            "memory usage: 756.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2agY98CU7HT7"
      },
      "source": [
        "We cannot see the info because there are too many variables in the dataset. So for now we are going to continue in this way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnsqyYnU8htG",
        "outputId": "01028eca-da01-4ef7-c953-ae2db7e330f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    477\n",
              "1    454\n",
              "Name: DX_GROUP, dtype: int64"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.DX_GROUP.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI52rF_QaucS"
      },
      "source": [
        "The data set it is not exactly balance, but it is almost balance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "yZvWPx9JbK97",
        "outputId": "9015980a-793b-4d14-8b5a-8eba3d67fb21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='DX_GROUP', ylabel='count'>"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x ='DX_GROUP', data = df, palette = 'flare')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mLAzOR7SRH"
      },
      "source": [
        "We cannot see a  issue with the groups. The dataset is almost balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bT5pa7aR0Pp",
        "outputId": "afee20fa-63b8-404a-da7a-2fccb8f71c51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(931, 104)"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQo_wadH7kP_"
      },
      "source": [
        "There are 931 rows and 104 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "CU97lGlQ8h2N",
        "outputId": "8b730dd2-0921-41e6-d9c4-4a70325ae073"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b6124c2-4ff1-4c43-96a0-8c452127bcd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>X</th>\n",
              "      <th>subject</th>\n",
              "      <th>SITE_ID</th>\n",
              "      <th>FILE_ID</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>SEX</th>\n",
              "      <th>HANDEDNESS_CATEGORY</th>\n",
              "      <th>HANDEDNESS_SCORES</th>\n",
              "      <th>FIQ</th>\n",
              "      <th>VIQ</th>\n",
              "      <th>PIQ</th>\n",
              "      <th>FIQ_TEST_TYPE</th>\n",
              "      <th>VIQ_TEST_TYPE</th>\n",
              "      <th>PIQ_TEST_TYPE</th>\n",
              "      <th>ADI_R_SOCIAL_TOTAL_A</th>\n",
              "      <th>ADI_R_VERBAL_TOTAL_BV</th>\n",
              "      <th>ADI_RRB_TOTAL_C</th>\n",
              "      <th>ADI_R_ONSET_TOTAL_D</th>\n",
              "      <th>ADI_R_RSRCH_RELIABLE</th>\n",
              "      <th>ADOS_MODULE</th>\n",
              "      <th>ADOS_TOTAL</th>\n",
              "      <th>ADOS_COMM</th>\n",
              "      <th>ADOS_SOCIAL</th>\n",
              "      <th>ADOS_STEREO_BEHAV</th>\n",
              "      <th>ADOS_RSRCH_RELIABLE</th>\n",
              "      <th>ADOS_GOTHAM_SOCAFFECT</th>\n",
              "      <th>ADOS_GOTHAM_RRB</th>\n",
              "      <th>ADOS_GOTHAM_TOTAL</th>\n",
              "      <th>ADOS_GOTHAM_SEVERITY</th>\n",
              "      <th>SRS_VERSION</th>\n",
              "      <th>SRS_RAW_TOTAL</th>\n",
              "      <th>SRS_AWARENESS</th>\n",
              "      <th>SRS_COGNITION</th>\n",
              "      <th>SRS_COMMUNICATION</th>\n",
              "      <th>SRS_MOTIVATION</th>\n",
              "      <th>SRS_MANNERISMS</th>\n",
              "      <th>SCQ_TOTAL</th>\n",
              "      <th>AQ_TOTAL</th>\n",
              "      <th>COMORBIDITY</th>\n",
              "      <th>CURRENT_MED_STATUS</th>\n",
              "      <th>MEDICATION_NAME</th>\n",
              "      <th>OFF_STIMULANTS_AT_SCAN</th>\n",
              "      <th>VINELAND_RECEPTIVE_V_SCALED</th>\n",
              "      <th>VINELAND_EXPRESSIVE_V_SCALED</th>\n",
              "      <th>VINELAND_WRITTEN_V_SCALED</th>\n",
              "      <th>VINELAND_COMMUNICATION_STANDARD</th>\n",
              "      <th>VINELAND_PERSONAL_V_SCALED</th>\n",
              "      <th>VINELAND_DOMESTIC_V_SCALED</th>\n",
              "      <th>VINELAND_COMMUNITY_V_SCALED</th>\n",
              "      <th>VINELAND_DAILYLVNG_STANDARD</th>\n",
              "      <th>VINELAND_INTERPERSONAL_V_SCALED</th>\n",
              "      <th>VINELAND_PLAY_V_SCALED</th>\n",
              "      <th>VINELAND_COPING_V_SCALED</th>\n",
              "      <th>VINELAND_SOCIAL_STANDARD</th>\n",
              "      <th>VINELAND_SUM_SCORES</th>\n",
              "      <th>VINELAND_ABC_STANDARD</th>\n",
              "      <th>VINELAND_INFORMANT</th>\n",
              "      <th>WISC_IV_VCI</th>\n",
              "      <th>WISC_IV_PRI</th>\n",
              "      <th>WISC_IV_WMI</th>\n",
              "      <th>WISC_IV_PSI</th>\n",
              "      <th>WISC_IV_SIM_SCALED</th>\n",
              "      <th>WISC_IV_VOCAB_SCALED</th>\n",
              "      <th>WISC_IV_INFO_SCALED</th>\n",
              "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
              "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
              "      <th>WISC_IV_MATRIX_SCALED</th>\n",
              "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
              "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
              "      <th>WISC_IV_CODING_SCALED</th>\n",
              "      <th>WISC_IV_SYM_SCALED</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>AGE_AT_MPRAGE</th>\n",
              "      <th>BMI</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>qc_rater_1</th>\n",
              "      <th>qc_notes_rater_1</th>\n",
              "      <th>qc_anat_rater_2</th>\n",
              "      <th>qc_anat_notes_rater_2</th>\n",
              "      <th>qc_func_rater_2</th>\n",
              "      <th>qc_func_notes_rater_2</th>\n",
              "      <th>qc_anat_rater_3</th>\n",
              "      <th>qc_anat_notes_rater_3</th>\n",
              "      <th>qc_func_rater_3</th>\n",
              "      <th>qc_func_notes_rater_3</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>814</td>\n",
              "      <td>51131</td>\n",
              "      <td>815</td>\n",
              "      <td>51131</td>\n",
              "      <td>NYU</td>\n",
              "      <td>NYU_0051131</td>\n",
              "      <td>2</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.00</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162</td>\n",
              "      <td>50237</td>\n",
              "      <td>163</td>\n",
              "      <td>50237</td>\n",
              "      <td>TRINITY</td>\n",
              "      <td>Trinity_0050237</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>118.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>863</td>\n",
              "      <td>51185</td>\n",
              "      <td>864</td>\n",
              "      <td>51185</td>\n",
              "      <td>STANFORD</td>\n",
              "      <td>Stanford_0051185</td>\n",
              "      <td>2</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>119.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>69.0</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>maybe</td>\n",
              "      <td>skull-striping fail;</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>668</td>\n",
              "      <td>50978</td>\n",
              "      <td>669</td>\n",
              "      <td>50978</td>\n",
              "      <td>NYU</td>\n",
              "      <td>NYU_0050978</td>\n",
              "      <td>1</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>WASI</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mood Disorder NOS</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.71</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>508</td>\n",
              "      <td>50653</td>\n",
              "      <td>509</td>\n",
              "      <td>50653</td>\n",
              "      <td>CMU</td>\n",
              "      <td>CMU_a_0050653</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>134.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>WISC</td>\n",
              "      <td>WISC</td>\n",
              "      <td>WISC</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>84.0</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>fail</td>\n",
              "      <td>ventral edge is cropped</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fail</td>\n",
              "      <td>ic-frontal-temporal-cerebellum</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b6124c2-4ff1-4c43-96a0-8c452127bcd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b6124c2-4ff1-4c43-96a0-8c452127bcd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b6124c2-4ff1-4c43-96a0-8c452127bcd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  SUB_ID    X  subject   SITE_ID           FILE_ID  DX_GROUP  \\\n",
              "0         814   51131  815    51131       NYU       NYU_0051131         2   \n",
              "1         162   50237  163    50237   TRINITY   Trinity_0050237         1   \n",
              "2         863   51185  864    51185  STANFORD  Stanford_0051185         2   \n",
              "3         668   50978  669    50978       NYU       NYU_0050978         1   \n",
              "4         508   50653  509    50653       CMU     CMU_a_0050653         1   \n",
              "\n",
              "   AGE_AT_SCAN  SEX HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ    VIQ  \\\n",
              "0      19.7300    1                 NaN               68.0  119.0  112.0   \n",
              "1      21.4200    1                   R                NaN  118.0  109.0   \n",
              "2       8.2464    1                   R                NaN  119.0  107.0   \n",
              "3       9.5800    1                 NaN               44.0  142.0  126.0   \n",
              "4      30.0000    1                   R                NaN  134.0  131.0   \n",
              "\n",
              "     PIQ FIQ_TEST_TYPE VIQ_TEST_TYPE PIQ_TEST_TYPE  ADI_R_SOCIAL_TOTAL_A  \\\n",
              "0  123.0          WASI          WASI          WASI                   NaN   \n",
              "1  116.0          WASI           NaN           NaN                  20.0   \n",
              "2  129.0          WASI          WASI          WASI                   NaN   \n",
              "3  149.0          WASI          WASI          WASI                  16.0   \n",
              "4  129.0          WISC          WISC          WISC                  20.0   \n",
              "\n",
              "   ADI_R_VERBAL_TOTAL_BV  ADI_RRB_TOTAL_C  ADI_R_ONSET_TOTAL_D  \\\n",
              "0                    NaN              NaN                  NaN   \n",
              "1                   18.0              5.0                  5.0   \n",
              "2                    NaN              NaN                  NaN   \n",
              "3                   17.0              5.0                  3.0   \n",
              "4                   13.0              3.0                  1.0   \n",
              "\n",
              "   ADI_R_RSRCH_RELIABLE  ADOS_MODULE  ADOS_TOTAL  ADOS_COMM  ADOS_SOCIAL  \\\n",
              "0                   NaN          NaN         NaN        NaN          NaN   \n",
              "1                   1.0          4.0        17.0        NaN          NaN   \n",
              "2                   NaN          NaN         NaN        NaN          NaN   \n",
              "3                   1.0          3.0         7.0        0.0          7.0   \n",
              "4                   1.0          4.0        18.0        5.0         13.0   \n",
              "\n",
              "   ADOS_STEREO_BEHAV  ADOS_RSRCH_RELIABLE  ADOS_GOTHAM_SOCAFFECT  \\\n",
              "0                NaN                  NaN                    NaN   \n",
              "1                NaN                  NaN                    NaN   \n",
              "2                NaN                  NaN                    NaN   \n",
              "3                3.0                  1.0                    6.0   \n",
              "4                3.0                  1.0                    NaN   \n",
              "\n",
              "   ADOS_GOTHAM_RRB  ADOS_GOTHAM_TOTAL  ADOS_GOTHAM_SEVERITY  SRS_VERSION  \\\n",
              "0              NaN                NaN                   NaN      -9999.0   \n",
              "1              NaN                NaN                   NaN          NaN   \n",
              "2              NaN                NaN                   NaN          NaN   \n",
              "3              4.0               10.0                   6.0          1.0   \n",
              "4              NaN                NaN                   NaN          NaN   \n",
              "\n",
              "   SRS_RAW_TOTAL  SRS_AWARENESS  SRS_COGNITION  SRS_COMMUNICATION  \\\n",
              "0        -9999.0            NaN            NaN                NaN   \n",
              "1            NaN            NaN            NaN                NaN   \n",
              "2            NaN            NaN            NaN                NaN   \n",
              "3           92.0            NaN            NaN                NaN   \n",
              "4            NaN            NaN            NaN                NaN   \n",
              "\n",
              "   SRS_MOTIVATION  SRS_MANNERISMS  SCQ_TOTAL  AQ_TOTAL        COMORBIDITY  \\\n",
              "0             NaN             NaN        NaN       NaN                NaN   \n",
              "1             NaN             NaN        NaN       NaN                NaN   \n",
              "2             NaN             NaN        NaN       NaN                NaN   \n",
              "3             NaN             NaN       15.0       NaN  Mood Disorder NOS   \n",
              "4             NaN             NaN        NaN       NaN                NaN   \n",
              "\n",
              "  CURRENT_MED_STATUS MEDICATION_NAME  OFF_STIMULANTS_AT_SCAN  \\\n",
              "0                  0             NaN                     NaN   \n",
              "1                  0             NaN                     NaN   \n",
              "2                NaN             NaN                     NaN   \n",
              "3                  0             NaN                     NaN   \n",
              "4                  0             NaN                 -9999.0   \n",
              "\n",
              "   VINELAND_RECEPTIVE_V_SCALED  VINELAND_EXPRESSIVE_V_SCALED  \\\n",
              "0                      -9999.0                       -9999.0   \n",
              "1                          NaN                           NaN   \n",
              "2                          NaN                           NaN   \n",
              "3                         13.0                          12.0   \n",
              "4                          NaN                           NaN   \n",
              "\n",
              "   VINELAND_WRITTEN_V_SCALED  VINELAND_COMMUNICATION_STANDARD  \\\n",
              "0                    -9999.0                          -9999.0   \n",
              "1                        NaN                              NaN   \n",
              "2                        NaN                              NaN   \n",
              "3                       16.0                             92.0   \n",
              "4                        NaN                              NaN   \n",
              "\n",
              "   VINELAND_PERSONAL_V_SCALED  VINELAND_DOMESTIC_V_SCALED  \\\n",
              "0                     -9999.0                     -9999.0   \n",
              "1                         NaN                         NaN   \n",
              "2                         NaN                         NaN   \n",
              "3                        17.0                        12.0   \n",
              "4                         NaN                         NaN   \n",
              "\n",
              "   VINELAND_COMMUNITY_V_SCALED  VINELAND_DAILYLVNG_STANDARD  \\\n",
              "0                      -9999.0                      -9999.0   \n",
              "1                          NaN                          NaN   \n",
              "2                          NaN                          NaN   \n",
              "3                         14.0                         95.0   \n",
              "4                          NaN                          NaN   \n",
              "\n",
              "   VINELAND_INTERPERSONAL_V_SCALED  VINELAND_PLAY_V_SCALED  \\\n",
              "0                          -9999.0                 -9999.0   \n",
              "1                              NaN                     NaN   \n",
              "2                              NaN                     NaN   \n",
              "3                              9.0                    13.0   \n",
              "4                              NaN                     NaN   \n",
              "\n",
              "   VINELAND_COPING_V_SCALED  VINELAND_SOCIAL_STANDARD  VINELAND_SUM_SCORES  \\\n",
              "0                   -9999.0                   -9999.0              -9999.0   \n",
              "1                       NaN                       NaN                  NaN   \n",
              "2                       NaN                       NaN                  NaN   \n",
              "3                      13.0                      82.0                269.0   \n",
              "4                       NaN                       NaN                  NaN   \n",
              "\n",
              "   VINELAND_ABC_STANDARD  VINELAND_INFORMANT  WISC_IV_VCI  WISC_IV_PRI  \\\n",
              "0                -9999.0             -9999.0          NaN          NaN   \n",
              "1                    NaN                 NaN          NaN          NaN   \n",
              "2                    NaN                 NaN          NaN          NaN   \n",
              "3                   88.0                 1.0          NaN          NaN   \n",
              "4                    NaN                 NaN          NaN          NaN   \n",
              "\n",
              "   WISC_IV_WMI  WISC_IV_PSI  WISC_IV_SIM_SCALED  WISC_IV_VOCAB_SCALED  \\\n",
              "0          NaN          NaN                 NaN                   NaN   \n",
              "1          NaN          NaN                 NaN                   NaN   \n",
              "2          NaN          NaN                 NaN                   NaN   \n",
              "3          NaN          NaN                 NaN                   NaN   \n",
              "4          NaN          NaN                 NaN                   NaN   \n",
              "\n",
              "   WISC_IV_INFO_SCALED  WISC_IV_BLK_DSN_SCALED  WISC_IV_PIC_CON_SCALED  \\\n",
              "0                  NaN                     NaN                     NaN   \n",
              "1                  NaN                     NaN                     NaN   \n",
              "2                  NaN                     NaN                     NaN   \n",
              "3                  NaN                     NaN                     NaN   \n",
              "4                  NaN                     NaN                     NaN   \n",
              "\n",
              "   WISC_IV_MATRIX_SCALED  WISC_IV_DIGIT_SPAN_SCALED  WISC_IV_LET_NUM_SCALED  \\\n",
              "0                    NaN                        NaN                     NaN   \n",
              "1                    NaN                        NaN                     NaN   \n",
              "2                    NaN                        NaN                     NaN   \n",
              "3                    NaN                        NaN                     NaN   \n",
              "4                    NaN                        NaN                     NaN   \n",
              "\n",
              "   WISC_IV_CODING_SCALED  WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  \\\n",
              "0                    NaN                 NaN                   1   \n",
              "1                    NaN                 NaN                   2   \n",
              "2                    NaN                 NaN                   2   \n",
              "3                    NaN                 NaN                   1   \n",
              "4                    NaN                 NaN                   2   \n",
              "\n",
              "   AGE_AT_MPRAGE      BMI   anat_cnr   anat_efc  anat_fber  anat_fwhm  \\\n",
              "0            NaN -9999.00  10.674176   0.616051  89.045514   3.509732   \n",
              "1            NaN      NaN   7.004004   1.674990  11.113986   4.425869   \n",
              "2            NaN      NaN   9.180373  14.838937   0.029120   2.824676   \n",
              "3            NaN    13.71   9.087565   0.517920  78.004528   3.220905   \n",
              "4            NaN      NaN  26.045369   4.167438  32.931736   3.423460   \n",
              "\n",
              "   anat_qi1   anat_snr  func_efc   func_fber  func_fwhm  func_dvars  \\\n",
              "0  0.067764  12.866070  0.534295   78.296410   1.765660    1.018414   \n",
              "1  0.075520  10.833468  0.428382  137.815548   1.955725    1.064568   \n",
              "2  0.241977   9.159445  0.555808   59.038003   2.772167    1.302140   \n",
              "3  0.055056  10.456115  0.485962  142.036348   2.057008    0.938920   \n",
              "4  0.058810  68.951286  0.585246   88.589366   1.680437    1.156320   \n",
              "\n",
              "   func_outlier  func_quality  func_mean_fd  func_num_fd  func_perc_fd  \\\n",
              "0      0.006217      0.014129      0.032827          2.0      1.104972   \n",
              "1      0.002349      0.008713      0.078301          7.0      4.635762   \n",
              "2      0.007001      0.007197      0.181608         69.0     28.630705   \n",
              "3      0.006253      0.011202      0.030118          1.0      0.552486   \n",
              "4      0.001147      0.007730      0.187709         84.0     34.854772   \n",
              "\n",
              "   func_gsr qc_rater_1         qc_notes_rater_1 qc_anat_rater_2  \\\n",
              "0 -0.001329         OK                      NaN              OK   \n",
              "1  0.010631         OK                      NaN              OK   \n",
              "2  0.036467         OK                      NaN           maybe   \n",
              "3 -0.010039         OK                      NaN              OK   \n",
              "4  0.079297       fail  ventral edge is cropped              OK   \n",
              "\n",
              "  qc_anat_notes_rater_2 qc_func_rater_2           qc_func_notes_rater_2  \\\n",
              "0                   NaN              OK                             NaN   \n",
              "1                   NaN              OK                             NaN   \n",
              "2  skull-striping fail;              OK                             NaN   \n",
              "3                   NaN              OK                             NaN   \n",
              "4                   NaN            fail  ic-frontal-temporal-cerebellum   \n",
              "\n",
              "  qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3 qc_func_notes_rater_3  \\\n",
              "0              OK                   NaN              OK                   NaN   \n",
              "1              OK                   NaN              OK                   NaN   \n",
              "2              OK                   NaN              OK                   NaN   \n",
              "3              OK                   NaN              OK                   NaN   \n",
              "4              OK                   NaN              OK                   NaN   \n",
              "\n",
              "   SUB_IN_SMP  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           0  \n",
              "4           0  "
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb-WserlrQ7i"
      },
      "source": [
        "## Dealing with missing values and Filtering the data\n",
        "\n",
        "To deal with missing values and filter the dataset  with take the reference the articles that mentioned that they keeped just the columns with 10% or less with missing values. The other we are going to fill with the predicted mean data imputation method since the missing data was assumed to be missing at random(as the article mentioned). In the article mentioned that they used MICE imputation(‘Multiple Imputation by Chained Equation’)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9j1Ggbt-dX4"
      },
      "source": [
        "### Filter the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9au5B1XOmMqI",
        "outputId": "dfc16101-c78c-4955-9d1a-bfb0517b421d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "qc_func_notes_rater_3     False\n",
              "qc_notes_rater_1          False\n",
              "WISC_IV_SIM_SCALED        False\n",
              "WISC_IV_BLK_DSN_SCALED    False\n",
              "WISC_IV_VCI               False\n",
              "                          ...  \n",
              "FILE_ID                    True\n",
              "SITE_ID                    True\n",
              "subject                    True\n",
              "X                          True\n",
              "SUB_IN_SMP                 True\n",
              "Length: 104, dtype: bool"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(((df.isnull().sum().sort_values(ascending=False)/len(df))*100)<=10)# we can see the variables that are more than 90% of missing values as False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOzdUdYvCgCO",
        "outputId": "e36d5dcf-1b4a-414d-8f1d-e2898bec95d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FIQ                   26.0\n",
              "anat_snr               1.0\n",
              "func_efc               1.0\n",
              "func_perc_fd           1.0\n",
              "func_num_fd            1.0\n",
              "func_mean_fd           1.0\n",
              "func_quality           1.0\n",
              "func_outlier           1.0\n",
              "func_dvars             1.0\n",
              "func_fwhm              1.0\n",
              "func_fber              1.0\n",
              "func_gsr               1.0\n",
              "anat_qi1               1.0\n",
              "anat_fwhm              1.0\n",
              "anat_fber              1.0\n",
              "anat_efc               1.0\n",
              "anat_cnr               1.0\n",
              "qc_anat_rater_2        0.0\n",
              "qc_rater_1             0.0\n",
              "qc_func_rater_3        0.0\n",
              "qc_anat_rater_3        0.0\n",
              "qc_func_rater_2        0.0\n",
              "Unnamed: 0             0.0\n",
              "EYE_STATUS_AT_SCAN     0.0\n",
              "SUB_ID                 0.0\n",
              "SEX                    0.0\n",
              "AGE_AT_SCAN            0.0\n",
              "DX_GROUP               0.0\n",
              "FILE_ID                0.0\n",
              "SITE_ID                0.0\n",
              "subject                0.0\n",
              "X                      0.0\n",
              "SUB_IN_SMP             0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum().sort_values(ascending=False).where(lambda sum: (sum/len(df))*100<=10).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U--Ha0L-m3_o",
        "outputId": "4531f624-2e44-4880-f405-31af68b8d94f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['FIQ', 'anat_snr', 'func_efc', 'func_perc_fd', 'func_num_fd',\n",
              "       'func_mean_fd', 'func_quality', 'func_outlier', 'func_dvars',\n",
              "       'func_fwhm', 'func_fber', 'func_gsr', 'anat_qi1', 'anat_fwhm',\n",
              "       'anat_fber', 'anat_efc', 'anat_cnr', 'qc_anat_rater_2', 'qc_rater_1',\n",
              "       'qc_func_rater_3', 'qc_anat_rater_3', 'qc_func_rater_2', 'Unnamed: 0',\n",
              "       'EYE_STATUS_AT_SCAN', 'SUB_ID', 'SEX', 'AGE_AT_SCAN', 'DX_GROUP',\n",
              "       'FILE_ID', 'SITE_ID', 'subject', 'X', 'SUB_IN_SMP'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns_10missing_values =df.isnull().sum().sort_values(ascending=False).where(lambda sum: (sum/len(df))*100<=10).dropna().keys()\n",
        "columns_10missing_values# Filtering the data with less than 10% of missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "HIrHuds38h5W",
        "outputId": "74708c17-b830-4131-d755-51720311a9ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02932ba1-e162-4e48-9775-d380842ce7c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>qc_anat_rater_2</th>\n",
              "      <th>qc_rater_1</th>\n",
              "      <th>qc_func_rater_3</th>\n",
              "      <th>qc_anat_rater_3</th>\n",
              "      <th>qc_func_rater_2</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SEX</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>FILE_ID</th>\n",
              "      <th>SITE_ID</th>\n",
              "      <th>subject</th>\n",
              "      <th>X</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>814</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>2</td>\n",
              "      <td>NYU_0051131</td>\n",
              "      <td>NYU</td>\n",
              "      <td>51131</td>\n",
              "      <td>815</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>162</td>\n",
              "      <td>2</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>Trinity_0050237</td>\n",
              "      <td>TRINITY</td>\n",
              "      <td>50237</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>maybe</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>863</td>\n",
              "      <td>2</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>Stanford_0051185</td>\n",
              "      <td>STANFORD</td>\n",
              "      <td>51185</td>\n",
              "      <td>864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>668</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>1</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU_0050978</td>\n",
              "      <td>NYU</td>\n",
              "      <td>50978</td>\n",
              "      <td>669</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>OK</td>\n",
              "      <td>fail</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>fail</td>\n",
              "      <td>508</td>\n",
              "      <td>2</td>\n",
              "      <td>50653</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>CMU_a_0050653</td>\n",
              "      <td>CMU</td>\n",
              "      <td>50653</td>\n",
              "      <td>509</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>103.0</td>\n",
              "      <td>254.347101</td>\n",
              "      <td>0.490541</td>\n",
              "      <td>1.324503</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.045737</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>1.010008</td>\n",
              "      <td>2.065640</td>\n",
              "      <td>95.257385</td>\n",
              "      <td>0.038512</td>\n",
              "      <td>0.092700</td>\n",
              "      <td>3.724990</td>\n",
              "      <td>234.970752</td>\n",
              "      <td>-7.639415</td>\n",
              "      <td>4.605309</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>maybe</td>\n",
              "      <td>1068</td>\n",
              "      <td>2</td>\n",
              "      <td>51482</td>\n",
              "      <td>2</td>\n",
              "      <td>21.1000</td>\n",
              "      <td>2</td>\n",
              "      <td>Caltech_0051482</td>\n",
              "      <td>CALTECH</td>\n",
              "      <td>51482</td>\n",
              "      <td>1069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>107.5</td>\n",
              "      <td>18.573171</td>\n",
              "      <td>0.586351</td>\n",
              "      <td>24.584718</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.191137</td>\n",
              "      <td>0.026467</td>\n",
              "      <td>0.006191</td>\n",
              "      <td>1.023363</td>\n",
              "      <td>2.568014</td>\n",
              "      <td>65.761519</td>\n",
              "      <td>0.061120</td>\n",
              "      <td>0.002402</td>\n",
              "      <td>2.608884</td>\n",
              "      <td>0.265646</td>\n",
              "      <td>9.963586</td>\n",
              "      <td>10.985865</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>50278</td>\n",
              "      <td>2</td>\n",
              "      <td>11.3000</td>\n",
              "      <td>1</td>\n",
              "      <td>UM_1_0050278</td>\n",
              "      <td>UM_1</td>\n",
              "      <td>50278</td>\n",
              "      <td>202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>92.0</td>\n",
              "      <td>20.048159</td>\n",
              "      <td>0.519434</td>\n",
              "      <td>8.298755</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.087332</td>\n",
              "      <td>0.020164</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>1.053701</td>\n",
              "      <td>1.892772</td>\n",
              "      <td>70.936407</td>\n",
              "      <td>0.032019</td>\n",
              "      <td>0.042362</td>\n",
              "      <td>4.878726</td>\n",
              "      <td>5.028586</td>\n",
              "      <td>2.316845</td>\n",
              "      <td>13.311842</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>385</td>\n",
              "      <td>1</td>\n",
              "      <td>50477</td>\n",
              "      <td>1</td>\n",
              "      <td>20.1807</td>\n",
              "      <td>1</td>\n",
              "      <td>USM_0050477</td>\n",
              "      <td>USM</td>\n",
              "      <td>50477</td>\n",
              "      <td>386</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>132.0</td>\n",
              "      <td>12.139245</td>\n",
              "      <td>0.501172</td>\n",
              "      <td>9.944751</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.111081</td>\n",
              "      <td>0.020851</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>0.895435</td>\n",
              "      <td>1.964289</td>\n",
              "      <td>134.300311</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>0.088045</td>\n",
              "      <td>3.485226</td>\n",
              "      <td>140.617266</td>\n",
              "      <td>0.454438</td>\n",
              "      <td>11.674108</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>655</td>\n",
              "      <td>1</td>\n",
              "      <td>50965</td>\n",
              "      <td>1</td>\n",
              "      <td>9.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU_0050965</td>\n",
              "      <td>NYU</td>\n",
              "      <td>50965</td>\n",
              "      <td>656</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>118.0</td>\n",
              "      <td>19.711215</td>\n",
              "      <td>0.602443</td>\n",
              "      <td>3.305785</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.061895</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>1.014639</td>\n",
              "      <td>1.739131</td>\n",
              "      <td>48.866041</td>\n",
              "      <td>0.052086</td>\n",
              "      <td>0.080716</td>\n",
              "      <td>3.590950</td>\n",
              "      <td>7.669491</td>\n",
              "      <td>2.272357</td>\n",
              "      <td>8.771666</td>\n",
              "      <td>maybe</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>OK</td>\n",
              "      <td>maybe</td>\n",
              "      <td>1014</td>\n",
              "      <td>2</td>\n",
              "      <td>51346</td>\n",
              "      <td>1</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>MaxMun_c_0051346</td>\n",
              "      <td>MAX_MUN</td>\n",
              "      <td>51346</td>\n",
              "      <td>1015</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02932ba1-e162-4e48-9775-d380842ce7c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02932ba1-e162-4e48-9775-d380842ce7c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02932ba1-e162-4e48-9775-d380842ce7c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       FIQ    anat_snr  func_efc  func_perc_fd  func_num_fd  func_mean_fd  \\\n",
              "0    119.0   12.866070  0.534295      1.104972          2.0      0.032827   \n",
              "1    118.0   10.833468  0.428382      4.635762          7.0      0.078301   \n",
              "2    119.0    9.159445  0.555808     28.630705         69.0      0.181608   \n",
              "3    142.0   10.456115  0.485962      0.552486          1.0      0.030118   \n",
              "4    134.0   68.951286  0.585246     34.854772         84.0      0.187709   \n",
              "..     ...         ...       ...           ...          ...           ...   \n",
              "926  103.0  254.347101  0.490541      1.324503          2.0      0.045737   \n",
              "927  107.5   18.573171  0.586351     24.584718         74.0      0.191137   \n",
              "928   92.0   20.048159  0.519434      8.298755         20.0      0.087332   \n",
              "929  132.0   12.139245  0.501172      9.944751         18.0      0.111081   \n",
              "930  118.0   19.711215  0.602443      3.305785          4.0      0.061895   \n",
              "\n",
              "     func_quality  func_outlier  func_dvars  func_fwhm   func_fber  func_gsr  \\\n",
              "0        0.014129      0.006217    1.018414   1.765660   78.296410 -0.001329   \n",
              "1        0.008713      0.002349    1.064568   1.955725  137.815548  0.010631   \n",
              "2        0.007197      0.007001    1.302140   2.772167   59.038003  0.036467   \n",
              "3        0.011202      0.006253    0.938920   2.057008  142.036348 -0.010039   \n",
              "4        0.007730      0.001147    1.156320   1.680437   88.589366  0.079297   \n",
              "..            ...           ...         ...        ...         ...       ...   \n",
              "926      0.003968      0.000624    1.010008   2.065640   95.257385  0.038512   \n",
              "927      0.026467      0.006191    1.023363   2.568014   65.761519  0.061120   \n",
              "928      0.020164      0.002621    1.053701   1.892772   70.936407  0.032019   \n",
              "929      0.020851      0.006488    0.895435   1.964289  134.300311 -0.000354   \n",
              "930      0.010230      0.001108    1.014639   1.739131   48.866041  0.052086   \n",
              "\n",
              "     anat_qi1  anat_fwhm   anat_fber   anat_efc   anat_cnr qc_anat_rater_2  \\\n",
              "0    0.067764   3.509732   89.045514   0.616051  10.674176              OK   \n",
              "1    0.075520   4.425869   11.113986   1.674990   7.004004              OK   \n",
              "2    0.241977   2.824676    0.029120  14.838937   9.180373           maybe   \n",
              "3    0.055056   3.220905   78.004528   0.517920   9.087565              OK   \n",
              "4    0.058810   3.423460   32.931736   4.167438  26.045369              OK   \n",
              "..        ...        ...         ...        ...        ...             ...   \n",
              "926  0.092700   3.724990  234.970752  -7.639415   4.605309              OK   \n",
              "927  0.002402   2.608884    0.265646   9.963586  10.985865              OK   \n",
              "928  0.042362   4.878726    5.028586   2.316845  13.311842              OK   \n",
              "929  0.088045   3.485226  140.617266   0.454438  11.674108              OK   \n",
              "930  0.080716   3.590950    7.669491   2.272357   8.771666           maybe   \n",
              "\n",
              "    qc_rater_1 qc_func_rater_3 qc_anat_rater_3 qc_func_rater_2  Unnamed: 0  \\\n",
              "0           OK              OK              OK              OK         814   \n",
              "1           OK              OK              OK              OK         162   \n",
              "2           OK              OK              OK              OK         863   \n",
              "3           OK              OK              OK              OK         668   \n",
              "4         fail              OK              OK            fail         508   \n",
              "..         ...             ...             ...             ...         ...   \n",
              "926         OK              OK              OK           maybe        1068   \n",
              "927         OK              OK              OK              OK         201   \n",
              "928         OK              OK              OK              OK         385   \n",
              "929         OK              OK              OK              OK         655   \n",
              "930         OK              OK              OK           maybe        1014   \n",
              "\n",
              "     EYE_STATUS_AT_SCAN  SUB_ID  SEX  AGE_AT_SCAN  DX_GROUP           FILE_ID  \\\n",
              "0                     1   51131    1      19.7300         2       NYU_0051131   \n",
              "1                     2   50237    1      21.4200         1   Trinity_0050237   \n",
              "2                     2   51185    1       8.2464         2  Stanford_0051185   \n",
              "3                     1   50978    1       9.5800         1       NYU_0050978   \n",
              "4                     2   50653    1      30.0000         1     CMU_a_0050653   \n",
              "..                  ...     ...  ...          ...       ...               ...   \n",
              "926                   2   51482    2      21.1000         2   Caltech_0051482   \n",
              "927                   1   50278    2      11.3000         1      UM_1_0050278   \n",
              "928                   1   50477    1      20.1807         1       USM_0050477   \n",
              "929                   1   50965    1       9.2500         1       NYU_0050965   \n",
              "930                   2   51346    1      25.0000         2  MaxMun_c_0051346   \n",
              "\n",
              "      SITE_ID  subject     X  SUB_IN_SMP  \n",
              "0         NYU    51131   815           1  \n",
              "1     TRINITY    50237   163           1  \n",
              "2    STANFORD    51185   864           1  \n",
              "3         NYU    50978   669           0  \n",
              "4         CMU    50653   509           0  \n",
              "..        ...      ...   ...         ...  \n",
              "926   CALTECH    51482  1069           0  \n",
              "927      UM_1    50278   202           0  \n",
              "928       USM    50477   386           1  \n",
              "929       NYU    50965   656           1  \n",
              "930   MAX_MUN    51346  1015           1  \n",
              "\n",
              "[931 rows x 33 columns]"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#DF Filter\n",
        "df=df.loc[:, columns_10missing_values]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mUirSiuchIw"
      },
      "source": [
        "We found  that the dataset filetered has categorical variables and we have to converted as dummy variables to proceed.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPSGrb6PDOlW",
        "outputId": "79cef423-796d-498f-f018-b36fafe0bef1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['qc_anat_rater_2', 'qc_rater_1', 'qc_func_rater_3', 'qc_anat_rater_3',\n",
              "       'qc_func_rater_2'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var=df.loc[:,\"qc_anat_rater_2\":\"qc_func_rater_2\"].columns\n",
        "var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "_LnsvS7pDsdV",
        "outputId": "f7848547-ad64-47fc-988a-aedada0a339e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4a4bb039-12b1-47d2-a124-64abc242ec1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SEX</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>FILE_ID</th>\n",
              "      <th>SITE_ID</th>\n",
              "      <th>subject</th>\n",
              "      <th>X</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "      <th>qc_anat_rater_2_fail</th>\n",
              "      <th>qc_anat_rater_2_maybe</th>\n",
              "      <th>qc_rater_1_fail</th>\n",
              "      <th>qc_rater_1_maybe</th>\n",
              "      <th>qc_func_rater_3_fail</th>\n",
              "      <th>qc_anat_rater_3_fail</th>\n",
              "      <th>qc_func_rater_2_fail</th>\n",
              "      <th>qc_func_rater_2_maybe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>814</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>2</td>\n",
              "      <td>NYU_0051131</td>\n",
              "      <td>NYU</td>\n",
              "      <td>51131</td>\n",
              "      <td>815</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>162</td>\n",
              "      <td>2</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>Trinity_0050237</td>\n",
              "      <td>TRINITY</td>\n",
              "      <td>50237</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>863</td>\n",
              "      <td>2</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>Stanford_0051185</td>\n",
              "      <td>STANFORD</td>\n",
              "      <td>51185</td>\n",
              "      <td>864</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>668</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>1</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU_0050978</td>\n",
              "      <td>NYU</td>\n",
              "      <td>50978</td>\n",
              "      <td>669</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>508</td>\n",
              "      <td>2</td>\n",
              "      <td>50653</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>CMU_a_0050653</td>\n",
              "      <td>CMU</td>\n",
              "      <td>50653</td>\n",
              "      <td>509</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>103.0</td>\n",
              "      <td>254.347101</td>\n",
              "      <td>0.490541</td>\n",
              "      <td>1.324503</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.045737</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>1.010008</td>\n",
              "      <td>2.065640</td>\n",
              "      <td>95.257385</td>\n",
              "      <td>0.038512</td>\n",
              "      <td>0.092700</td>\n",
              "      <td>3.724990</td>\n",
              "      <td>234.970752</td>\n",
              "      <td>-7.639415</td>\n",
              "      <td>4.605309</td>\n",
              "      <td>1068</td>\n",
              "      <td>2</td>\n",
              "      <td>51482</td>\n",
              "      <td>2</td>\n",
              "      <td>21.1000</td>\n",
              "      <td>2</td>\n",
              "      <td>Caltech_0051482</td>\n",
              "      <td>CALTECH</td>\n",
              "      <td>51482</td>\n",
              "      <td>1069</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>107.5</td>\n",
              "      <td>18.573171</td>\n",
              "      <td>0.586351</td>\n",
              "      <td>24.584718</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.191137</td>\n",
              "      <td>0.026467</td>\n",
              "      <td>0.006191</td>\n",
              "      <td>1.023363</td>\n",
              "      <td>2.568014</td>\n",
              "      <td>65.761519</td>\n",
              "      <td>0.061120</td>\n",
              "      <td>0.002402</td>\n",
              "      <td>2.608884</td>\n",
              "      <td>0.265646</td>\n",
              "      <td>9.963586</td>\n",
              "      <td>10.985865</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>50278</td>\n",
              "      <td>2</td>\n",
              "      <td>11.3000</td>\n",
              "      <td>1</td>\n",
              "      <td>UM_1_0050278</td>\n",
              "      <td>UM_1</td>\n",
              "      <td>50278</td>\n",
              "      <td>202</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>92.0</td>\n",
              "      <td>20.048159</td>\n",
              "      <td>0.519434</td>\n",
              "      <td>8.298755</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.087332</td>\n",
              "      <td>0.020164</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>1.053701</td>\n",
              "      <td>1.892772</td>\n",
              "      <td>70.936407</td>\n",
              "      <td>0.032019</td>\n",
              "      <td>0.042362</td>\n",
              "      <td>4.878726</td>\n",
              "      <td>5.028586</td>\n",
              "      <td>2.316845</td>\n",
              "      <td>13.311842</td>\n",
              "      <td>385</td>\n",
              "      <td>1</td>\n",
              "      <td>50477</td>\n",
              "      <td>1</td>\n",
              "      <td>20.1807</td>\n",
              "      <td>1</td>\n",
              "      <td>USM_0050477</td>\n",
              "      <td>USM</td>\n",
              "      <td>50477</td>\n",
              "      <td>386</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>132.0</td>\n",
              "      <td>12.139245</td>\n",
              "      <td>0.501172</td>\n",
              "      <td>9.944751</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.111081</td>\n",
              "      <td>0.020851</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>0.895435</td>\n",
              "      <td>1.964289</td>\n",
              "      <td>134.300311</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>0.088045</td>\n",
              "      <td>3.485226</td>\n",
              "      <td>140.617266</td>\n",
              "      <td>0.454438</td>\n",
              "      <td>11.674108</td>\n",
              "      <td>655</td>\n",
              "      <td>1</td>\n",
              "      <td>50965</td>\n",
              "      <td>1</td>\n",
              "      <td>9.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU_0050965</td>\n",
              "      <td>NYU</td>\n",
              "      <td>50965</td>\n",
              "      <td>656</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>118.0</td>\n",
              "      <td>19.711215</td>\n",
              "      <td>0.602443</td>\n",
              "      <td>3.305785</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.061895</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>1.014639</td>\n",
              "      <td>1.739131</td>\n",
              "      <td>48.866041</td>\n",
              "      <td>0.052086</td>\n",
              "      <td>0.080716</td>\n",
              "      <td>3.590950</td>\n",
              "      <td>7.669491</td>\n",
              "      <td>2.272357</td>\n",
              "      <td>8.771666</td>\n",
              "      <td>1014</td>\n",
              "      <td>2</td>\n",
              "      <td>51346</td>\n",
              "      <td>1</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>MaxMun_c_0051346</td>\n",
              "      <td>MAX_MUN</td>\n",
              "      <td>51346</td>\n",
              "      <td>1015</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a4bb039-12b1-47d2-a124-64abc242ec1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a4bb039-12b1-47d2-a124-64abc242ec1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a4bb039-12b1-47d2-a124-64abc242ec1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       FIQ    anat_snr  func_efc  func_perc_fd  func_num_fd  func_mean_fd  \\\n",
              "0    119.0   12.866070  0.534295      1.104972          2.0      0.032827   \n",
              "1    118.0   10.833468  0.428382      4.635762          7.0      0.078301   \n",
              "2    119.0    9.159445  0.555808     28.630705         69.0      0.181608   \n",
              "3    142.0   10.456115  0.485962      0.552486          1.0      0.030118   \n",
              "4    134.0   68.951286  0.585246     34.854772         84.0      0.187709   \n",
              "..     ...         ...       ...           ...          ...           ...   \n",
              "926  103.0  254.347101  0.490541      1.324503          2.0      0.045737   \n",
              "927  107.5   18.573171  0.586351     24.584718         74.0      0.191137   \n",
              "928   92.0   20.048159  0.519434      8.298755         20.0      0.087332   \n",
              "929  132.0   12.139245  0.501172      9.944751         18.0      0.111081   \n",
              "930  118.0   19.711215  0.602443      3.305785          4.0      0.061895   \n",
              "\n",
              "     func_quality  func_outlier  func_dvars  func_fwhm   func_fber  func_gsr  \\\n",
              "0        0.014129      0.006217    1.018414   1.765660   78.296410 -0.001329   \n",
              "1        0.008713      0.002349    1.064568   1.955725  137.815548  0.010631   \n",
              "2        0.007197      0.007001    1.302140   2.772167   59.038003  0.036467   \n",
              "3        0.011202      0.006253    0.938920   2.057008  142.036348 -0.010039   \n",
              "4        0.007730      0.001147    1.156320   1.680437   88.589366  0.079297   \n",
              "..            ...           ...         ...        ...         ...       ...   \n",
              "926      0.003968      0.000624    1.010008   2.065640   95.257385  0.038512   \n",
              "927      0.026467      0.006191    1.023363   2.568014   65.761519  0.061120   \n",
              "928      0.020164      0.002621    1.053701   1.892772   70.936407  0.032019   \n",
              "929      0.020851      0.006488    0.895435   1.964289  134.300311 -0.000354   \n",
              "930      0.010230      0.001108    1.014639   1.739131   48.866041  0.052086   \n",
              "\n",
              "     anat_qi1  anat_fwhm   anat_fber   anat_efc   anat_cnr  Unnamed: 0  \\\n",
              "0    0.067764   3.509732   89.045514   0.616051  10.674176         814   \n",
              "1    0.075520   4.425869   11.113986   1.674990   7.004004         162   \n",
              "2    0.241977   2.824676    0.029120  14.838937   9.180373         863   \n",
              "3    0.055056   3.220905   78.004528   0.517920   9.087565         668   \n",
              "4    0.058810   3.423460   32.931736   4.167438  26.045369         508   \n",
              "..        ...        ...         ...        ...        ...         ...   \n",
              "926  0.092700   3.724990  234.970752  -7.639415   4.605309        1068   \n",
              "927  0.002402   2.608884    0.265646   9.963586  10.985865         201   \n",
              "928  0.042362   4.878726    5.028586   2.316845  13.311842         385   \n",
              "929  0.088045   3.485226  140.617266   0.454438  11.674108         655   \n",
              "930  0.080716   3.590950    7.669491   2.272357   8.771666        1014   \n",
              "\n",
              "     EYE_STATUS_AT_SCAN  SUB_ID  SEX  AGE_AT_SCAN  DX_GROUP           FILE_ID  \\\n",
              "0                     1   51131    1      19.7300         2       NYU_0051131   \n",
              "1                     2   50237    1      21.4200         1   Trinity_0050237   \n",
              "2                     2   51185    1       8.2464         2  Stanford_0051185   \n",
              "3                     1   50978    1       9.5800         1       NYU_0050978   \n",
              "4                     2   50653    1      30.0000         1     CMU_a_0050653   \n",
              "..                  ...     ...  ...          ...       ...               ...   \n",
              "926                   2   51482    2      21.1000         2   Caltech_0051482   \n",
              "927                   1   50278    2      11.3000         1      UM_1_0050278   \n",
              "928                   1   50477    1      20.1807         1       USM_0050477   \n",
              "929                   1   50965    1       9.2500         1       NYU_0050965   \n",
              "930                   2   51346    1      25.0000         2  MaxMun_c_0051346   \n",
              "\n",
              "      SITE_ID  subject     X  SUB_IN_SMP  qc_anat_rater_2_fail  \\\n",
              "0         NYU    51131   815           1                     0   \n",
              "1     TRINITY    50237   163           1                     0   \n",
              "2    STANFORD    51185   864           1                     0   \n",
              "3         NYU    50978   669           0                     0   \n",
              "4         CMU    50653   509           0                     0   \n",
              "..        ...      ...   ...         ...                   ...   \n",
              "926   CALTECH    51482  1069           0                     0   \n",
              "927      UM_1    50278   202           0                     0   \n",
              "928       USM    50477   386           1                     0   \n",
              "929       NYU    50965   656           1                     0   \n",
              "930   MAX_MUN    51346  1015           1                     0   \n",
              "\n",
              "     qc_anat_rater_2_maybe  qc_rater_1_fail  qc_rater_1_maybe  \\\n",
              "0                        0                0                 0   \n",
              "1                        0                0                 0   \n",
              "2                        1                0                 0   \n",
              "3                        0                0                 0   \n",
              "4                        0                1                 0   \n",
              "..                     ...              ...               ...   \n",
              "926                      0                0                 0   \n",
              "927                      0                0                 0   \n",
              "928                      0                0                 0   \n",
              "929                      0                0                 0   \n",
              "930                      1                0                 0   \n",
              "\n",
              "     qc_func_rater_3_fail  qc_anat_rater_3_fail  qc_func_rater_2_fail  \\\n",
              "0                       0                     0                     0   \n",
              "1                       0                     0                     0   \n",
              "2                       0                     0                     0   \n",
              "3                       0                     0                     0   \n",
              "4                       0                     0                     1   \n",
              "..                    ...                   ...                   ...   \n",
              "926                     0                     0                     0   \n",
              "927                     0                     0                     0   \n",
              "928                     0                     0                     0   \n",
              "929                     0                     0                     0   \n",
              "930                     0                     0                     0   \n",
              "\n",
              "     qc_func_rater_2_maybe  \n",
              "0                        0  \n",
              "1                        0  \n",
              "2                        0  \n",
              "3                        0  \n",
              "4                        0  \n",
              "..                     ...  \n",
              "926                      1  \n",
              "927                      0  \n",
              "928                      0  \n",
              "929                      0  \n",
              "930                      1  \n",
              "\n",
              "[931 rows x 36 columns]"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dummies=pd.get_dummies(df,columns=var,drop_first=True)\n",
        "df_dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRuiyZYUGA1B",
        "outputId": "bf6929cc-5453-498f-fe95-7b0f6523115d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['NYU', 'TRINITY', 'STANFORD', 'CMU', 'MAX_MUN', 'SBL', 'UM_1',\n",
              "       'YALE', 'UCLA_1', 'LEUVEN_2', 'CALTECH', 'UM_2', 'KKI', 'OHSU',\n",
              "       'LEUVEN_1', 'USM', 'UCLA_2', 'SDSU', 'OLIN', 'PITT'], dtype=object)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.SITE_ID.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy7NbQxZGC8d",
        "outputId": "0afe7ffb-9043-4374-b9c7-8e4e36056a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['NYU_0051131', 'Trinity_0050237', 'Stanford_0051185',\n",
              "       'NYU_0050978', 'CMU_a_0050653', 'MaxMun_d_0051357', 'SBL_0051569',\n",
              "       'NYU_0051153', 'SBL_0051580', 'UM_1_0050316', 'NYU_0051038',\n",
              "       'NYU_0050984', 'NYU_0050990', 'Yale_0050558', 'CMU_b_0050658',\n",
              "       'UCLA_1_0051221', 'Leuven_2_0050744', 'Caltech_0051476',\n",
              "       'UCLA_1_0051252', 'NYU_0051018', 'UM_2_0050387', 'KKI_0050816',\n",
              "       'Caltech_0051474', 'UM_1_0050377', 'NYU_0051010', 'Yale_0050578',\n",
              "       'OHSU_0050158', 'UM_1_0050296', 'Yale_0050577', 'Caltech_0051487',\n",
              "       'NYU_0050955', 'Yale_0050622', 'MaxMun_a_0051319',\n",
              "       'Leuven_1_0050690', 'USM_0050480', 'Trinity_0050248',\n",
              "       'Leuven_1_0050711', 'UCLA_2_0051314', 'USM_0050531', 'SBL_0051579',\n",
              "       'NYU_0051070', 'USM_0050437', 'Caltech_0051464',\n",
              "       'Stanford_0051180', 'MaxMun_b_0051325', 'Caltech_0051478',\n",
              "       'Stanford_0051187', 'Stanford_0051194', 'UM_2_0050421',\n",
              "       'NYU_0051063', 'UM_2_0050415', 'NYU_0051122', 'Stanford_0051179',\n",
              "       'Leuven_2_0050725', 'SDSU_0050215', 'Olin_0050112',\n",
              "       'UCLA_1_0051239', 'Leuven_2_0050746', 'Yale_0050618',\n",
              "       'USM_0050435', 'UCLA_2_0051301', 'OHSU_0050148', 'SDSU_0050182',\n",
              "       'Leuven_1_0050697', 'SBL_0051577', 'NYU_0050992',\n",
              "       'Trinity_0050251', 'NYU_0051041', 'Yale_0050620', 'UM_1_0050361',\n",
              "       'UCLA_1_0051231', 'Leuven_2_0050755', 'USM_0050481',\n",
              "       'Leuven_2_0050754', 'NYU_0051150', 'USM_0050499',\n",
              "       'MaxMun_c_0051338', 'USM_0050496', 'USM_0050519', 'Pitt_0050012',\n",
              "       'MaxMun_d_0051353', 'UCLA_1_0051276', 'Leuven_1_0050702',\n",
              "       'OHSU_0050171', 'UM_1_0050364', 'SDSU_0050206', 'OHSU_0050156',\n",
              "       'Pitt_0050045', 'NYU_0051095', 'KKI_0050779', 'UM_1_0050321',\n",
              "       'UCLA_1_0051266', 'USM_0050469', 'USM_0050438', 'Yale_0050575',\n",
              "       'UM_2_0050414', 'SDSU_0050214', 'UM_1_0050380', 'UM_1_0050293',\n",
              "       'USM_0050493', 'Stanford_0051182', 'Yale_0050607', 'NYU_0050996',\n",
              "       'Yale_0050627', 'UCLA_1_0051208', 'SDSU_0050200', 'Yale_0050563',\n",
              "       'Leuven_2_0050737', 'UM_2_0050386', 'SDSU_0050210', 'NYU_0050966',\n",
              "       'KKI_0050798', 'UM_1_0050272', 'UCLA_2_0051313', 'UM_1_0050362',\n",
              "       'NYU_0051015', 'Olin_0050129', 'NYU_0051081', 'UM_2_0050382',\n",
              "       'NYU_0051098', 'NYU_0051044', 'UCLA_2_0051312', 'UM_2_0050402',\n",
              "       'NYU_0051104', 'UCLA_1_0051212', 'UM_2_0050417', 'Trinity_0051132',\n",
              "       'NYU_0050974', 'NYU_0050985', 'NYU_0051014', 'Yale_0050556',\n",
              "       'MaxMun_c_0051348', 'Trinity_0050245', 'Leuven_1_0050688',\n",
              "       'Trinity_0050242', 'Pitt_0050034', 'NYU_0051000',\n",
              "       'Trinity_0051142', 'KKI_0050783', 'NYU_0051148', 'KKI_0050824',\n",
              "       'Stanford_0051160', 'SDSU_0050204', 'NYU_0051073', 'NYU_0051112',\n",
              "       'SDSU_0050211', 'OHSU_0050153', 'SBL_0051567', 'Pitt_0050059',\n",
              "       'UCLA_1_0051202', 'UCLA_2_0051291', 'Caltech_0051490',\n",
              "       'MaxMun_c_0051332', 'Pitt_0050043', 'MaxMun_a_0051373',\n",
              "       'UCLA_1_0051203', 'NYU_0051057', 'NYU_0051021', 'Leuven_2_0050747',\n",
              "       'SBL_0051576', 'Leuven_2_0050726', 'UM_1_0050288', 'KKI_0050819',\n",
              "       'UCLA_1_0051227', 'KKI_0050820', 'USM_0050433', 'UCLA_1_0051271',\n",
              "       'MaxMun_a_0051606', 'Caltech_0051480', 'Yale_0050624',\n",
              "       'NYU_0051110', 'Pitt_0050004', 'Caltech_0051468', 'NYU_0051058',\n",
              "       'NYU_0051052', 'NYU_0051114', 'CMU_b_0050657', 'UM_1_0050374',\n",
              "       'UM_1_0050353', 'Pitt_0050009', 'OHSU_0050167', 'Olin_0050124',\n",
              "       'NYU_0051030', 'NYU_0051091', 'Pitt_0050032', 'UCLA_1_0051217',\n",
              "       'Pitt_0050041', 'Stanford_0051177', 'NYU_0051082', 'KKI_0050782',\n",
              "       'NYU_0051007', 'Olin_0050121', 'SDSU_0050191', 'OHSU_0050149',\n",
              "       'UCLA_1_0051235', 'UM_1_0050310', 'UM_2_0050390', 'NYU_0050997',\n",
              "       'UCLA_1_0051220', 'NYU_0051071', 'Stanford_0051163',\n",
              "       'OHSU_0050166', 'MaxMun_d_0051352', 'Caltech_0051459',\n",
              "       'Stanford_0051192', 'NYU_0051006', 'NYU_0050981', 'NYU_0051054',\n",
              "       'Trinity_0050243', 'NYU_0051077', 'NYU_0050982', 'Yale_0050560',\n",
              "       'UM_1_0050334', 'Yale_0050557', 'CMU_a_0050649',\n",
              "       'Stanford_0051166', 'UM_1_0050332', 'OHSU_0050160', 'KKI_0050784',\n",
              "       'Stanford_0051198', 'Leuven_1_0050689', 'Leuven_1_0050709',\n",
              "       'Leuven_2_0050741', 'NYU_0051088', 'SBL_0051559', 'Olin_0050132',\n",
              "       'Trinity_0050271', 'UM_1_0050317', 'USM_0050509', 'Yale_0050572',\n",
              "       'Stanford_0051161', 'Caltech_0051488', 'USM_0050487',\n",
              "       'KKI_0050822', 'SDSU_0050205', 'USM_0050436', 'Pitt_0050011',\n",
              "       'Caltech_0051481', 'UCLA_1_0051258', 'NYU_0051084',\n",
              "       'UCLA_1_0051214', 'UM_1_0050291', 'NYU_0051097', 'CMU_a_0050654',\n",
              "       'NYU_0051039', 'UCLA_1_0051229', 'NYU_0051023', 'UM_2_0050407',\n",
              "       'Caltech_0051462', 'NYU_0051154', 'Olin_0050130',\n",
              "       'Trinity_0051139', 'UCLA_2_0051296', 'UM_1_0050340',\n",
              "       'Trinity_0050259', 'NYU_0051147', 'OHSU_0050159', 'UCLA_2_0051304',\n",
              "       'UCLA_1_0051228', 'USM_0050523', 'Olin_0050122', 'CMU_a_0050663',\n",
              "       'NYU_0050959', 'UM_1_0050322', 'UM_1_0050379', 'CMU_b_0050667',\n",
              "       'Stanford_0051183', 'UM_1_0050279', 'UM_1_0050277', 'NYU_0051047',\n",
              "       'MaxMun_c_0051343', 'MaxMun_b_0051326', 'SDSU_0050202',\n",
              "       'Pitt_0050040', 'MaxMun_b_0051322', 'NYU_0050968',\n",
              "       'UCLA_1_0051219', 'UM_1_0050359', 'NYU_0051124', 'Olin_0050119',\n",
              "       'MaxMun_a_0051369', 'Trinity_0050233', 'OHSU_0050146',\n",
              "       'UM_1_0050347', 'NYU_0051099', 'NYU_0050952', 'USM_0050530',\n",
              "       'UM_2_0050416', 'Pitt_0050020', 'USM_0050467', 'NYU_0051016',\n",
              "       'UM_1_0050282', 'UCLA_2_0051299', 'UM_1_0050369',\n",
              "       'Leuven_1_0050691', 'Caltech_0051486', 'USM_0050447',\n",
              "       'UCLA_2_0051311', 'MaxMun_c_0051340', 'Pitt_0050022',\n",
              "       'Caltech_0051472', 'SDSU_0050198', 'Yale_0050612', 'Yale_0050568',\n",
              "       'UCLA_1_0051215', 'CMU_b_0050669', 'UM_1_0050363', 'UM_2_0050404',\n",
              "       'USM_0050525', 'Olin_0050104', 'Pitt_0050008', 'SDSU_0050197',\n",
              "       'MaxMun_c_0051345', 'UCLA_1_0051216', 'USM_0050434',\n",
              "       'UM_2_0050399', 'SDSU_0050216', 'NYU_0050961', 'SDSU_0050201',\n",
              "       'MaxMun_c_0051336', 'NYU_0051089', 'UM_1_0050343',\n",
              "       'UCLA_1_0051282', 'KKI_0050823', 'UM_2_0050410', 'SDSU_0050189',\n",
              "       'SBL_0051582', 'CMU_a_0050647', 'NYU_0051059', 'KKI_0050802',\n",
              "       'Leuven_1_0050696', 'Pitt_0050027', 'Yale_0050611', 'NYU_0051067',\n",
              "       'Yale_0050613', 'USM_0050485', 'UCLA_2_0051303', 'CMU_a_0050668',\n",
              "       'UM_1_0050276', 'UM_1_0050301', 'MaxMun_c_0051333', 'SBL_0051571',\n",
              "       'UCLA_2_0051308', 'Yale_0050601', 'Pitt_0050013', 'USM_0050440',\n",
              "       'Caltech_0051465', 'Olin_0050106', 'NYU_0051001', 'NYU_0051056',\n",
              "       'UM_1_0050348', 'NYU_0051076', 'SDSU_0050208', 'NYU_0051048',\n",
              "       'Trinity_0051137', 'NYU_0051129', 'Yale_0050570', 'KKI_0050775',\n",
              "       'Trinity_0050260', 'UCLA_1_0051237', 'Trinity_0050240',\n",
              "       'Pitt_0050046', 'Yale_0050610', 'USM_0050502', 'Trinity_0050257',\n",
              "       'Stanford_0051168', 'UCLA_1_0051263', 'OHSU_0050157',\n",
              "       'SDSU_0050193', 'UCLA_2_0051300', 'Pitt_0050042', 'Pitt_0050005',\n",
              "       'NYU_0051118', 'NYU_0051003', 'NYU_0051096', 'Trinity_0050239',\n",
              "       'Yale_0050602', 'Trinity_0050265', 'UM_1_0050346',\n",
              "       'MaxMun_d_0051355', 'UCLA_1_0051205', 'USM_0050527',\n",
              "       'Leuven_2_0050752', 'OHSU_0050150', 'NYU_0050960', 'NYU_0051029',\n",
              "       'UCLA_2_0051292', 'UM_1_0050292', 'OHSU_0050164', 'Olin_0050102',\n",
              "       'NYU_0051008', 'NYU_0051042', 'UM_1_0050325', 'CMU_b_0050651',\n",
              "       'UCLA_1_0051201', 'KKI_0050807', 'Stanford_0051169',\n",
              "       'Trinity_0051140', 'UM_2_0050418', 'Pitt_0050007', 'USM_0050520',\n",
              "       'Pitt_0050024', 'Olin_0050109', 'Yale_0050554', 'USM_0050482',\n",
              "       'Yale_0050571', 'NYU_0051106', 'KKI_0050804', 'KKI_0050796',\n",
              "       'USM_0050444', 'Stanford_0051199', 'Yale_0050615', 'USM_0050492',\n",
              "       'NYU_0051020', 'UM_1_0050355', 'SDSU_0050213', 'Caltech_0051466',\n",
              "       'SDSU_0050187', 'NYU_0050956', 'NYU_0051012', 'UM_1_0050303',\n",
              "       'UCLA_1_0051213', 'Leuven_2_0050745', 'UM_1_0050324',\n",
              "       'USM_0050505', 'Yale_0050569', 'Pitt_0050023', 'NYU_0051105',\n",
              "       'NYU_0051156', 'NYU_0051035', 'UM_1_0050273', 'Trinity_0050269',\n",
              "       'NYU_0050987', 'UM_2_0050412', 'Trinity_0050252',\n",
              "       'Stanford_0051197', 'NYU_0051109', 'UCLA_2_0051317', 'NYU_0051149',\n",
              "       'Yale_0050561', 'NYU_0051111', 'Trinity_0050264',\n",
              "       'Leuven_2_0050739', 'Yale_0050617', 'KKI_0050797',\n",
              "       'Trinity_0051134', 'UCLA_1_0051254', 'KKI_0050815',\n",
              "       'Leuven_1_0050701', 'Caltech_0051461', 'Trinity_0050254',\n",
              "       'UM_1_0050304', 'UM_1_0050341', 'UCLA_2_0051295', 'Pitt_0050056',\n",
              "       'USM_0050497', 'NYU_0050999', 'Leuven_1_0050692', 'UM_1_0050366',\n",
              "       'NYU_0050973', 'NYU_0051094', 'USM_0050468', 'USM_0050528',\n",
              "       'NYU_0051078', 'NYU_0050989', 'OHSU_0050161', 'NYU_0050991',\n",
              "       'NYU_0051130', 'Pitt_0050038', 'MaxMun_d_0051356', 'KKI_0050803',\n",
              "       'NYU_0050970', 'NYU_0051024', 'NYU_0051074', 'UM_2_0050403',\n",
              "       'OHSU_0050168', 'KKI_0050788', 'KKI_0050791', 'USM_0050503',\n",
              "       'NYU_0051146', 'UCLA_1_0051223', 'Leuven_2_0050730',\n",
              "       'CMU_a_0050642', 'Yale_0050553', 'USM_0050449', 'NYU_0051102',\n",
              "       'Leuven_2_0050735', 'UCLA_2_0051307', 'UCLA_1_0051280',\n",
              "       'Yale_0050566', 'UCLA_1_0051273', 'Trinity_0050247',\n",
              "       'CMU_a_0050659', 'Leuven_2_0050722', 'UM_1_0050299',\n",
              "       'Stanford_0051190', 'Pitt_0050016', 'SBL_0051560', 'Pitt_0050025',\n",
              "       'USM_0050515', 'UM_1_0050274', 'Olin_0050125', 'Yale_0050616',\n",
              "       'CMU_a_0050646', 'Leuven_2_0050738', 'MaxMun_d_0051349',\n",
              "       'UCLA_1_0051281', 'MaxMun_d_0051359', 'NYU_0050995', 'USM_0050463',\n",
              "       'Yale_0050603', 'UCLA_1_0051204', 'UM_1_0050371',\n",
              "       'Stanford_0051165', 'NYU_0051107', 'Pitt_0050037', 'UM_1_0050300',\n",
              "       'Trinity_0050270', 'SBL_0051573', 'Trinity_0050266',\n",
              "       'UCLA_2_0051302', 'UM_1_0050320', 'Pitt_0050044', 'OHSU_0050145',\n",
              "       'UM_1_0050339', 'USM_0050526', 'Leuven_2_0050756', 'KKI_0050799',\n",
              "       'Trinity_0050262', 'USM_0050466', 'Stanford_0051191',\n",
              "       'MaxMun_d_0051361', 'Leuven_1_0050698', 'Olin_0050116',\n",
              "       'SDSU_0050194', 'UM_1_0050381', 'Caltech_0051483', 'NYU_0051033',\n",
              "       'SDSU_0050207', 'MaxMun_a_0051321', 'UCLA_2_0051293',\n",
              "       'UM_2_0050388', 'Leuven_2_0050727', 'SBL_0051583',\n",
              "       'MaxMun_a_0051363', 'Trinity_0050263', 'NYU_0051025',\n",
              "       'Pitt_0050058', 'KKI_0050812', 'Stanford_0051189', 'CMU_a_0050664',\n",
              "       'Olin_0050127', 'UM_1_0050308', 'SBL_0051564', 'UCLA_1_0051278',\n",
              "       'Pitt_0050035', 'Pitt_0050015', 'Olin_0050117', 'NYU_0050957',\n",
              "       'CMU_b_0050650', 'NYU_0051045', 'Leuven_1_0050700', 'Yale_0050564',\n",
              "       'Yale_0050565', 'USM_0050483', 'Trinity_0050241', 'UCLA_1_0051224',\n",
              "       'UCLA_1_0051238', 'CMU_b_0050645', 'UCLA_1_0051265',\n",
              "       'MaxMun_a_0051320', 'UM_2_0050419', 'KKI_0050821',\n",
              "       'Trinity_0050246', 'Caltech_0051471', 'Leuven_1_0050687',\n",
              "       'SBL_0051568', 'UCLA_1_0051262', 'UCLA_2_0051297',\n",
              "       'Stanford_0051178', 'Olin_0050103', 'UCLA_1_0051207',\n",
              "       'Trinity_0051141', 'SBL_0051558', 'UM_1_0050302', 'CMU_a_0050660',\n",
              "       'Pitt_0050051', 'UM_2_0050391', 'Pitt_0050026', 'USM_0050504',\n",
              "       'KKI_0050794', 'UM_1_0050314', 'SBL_0051581', 'Olin_0050107',\n",
              "       'CMU_a_0050666', 'UCLA_1_0051267', 'USM_0050500', 'Yale_0050614',\n",
              "       'KKI_0050792', 'USM_0050489', 'UM_1_0050330', 'NYU_0051009',\n",
              "       'NYU_0051117', 'KKI_0050786', 'CMU_b_0050648', 'NYU_0051085',\n",
              "       'SDSU_0050217', 'NYU_0050977', 'Yale_0050552', 'Caltech_0051479',\n",
              "       'Olin_0050114', 'UM_1_0050345', 'USM_0050529', 'Pitt_0050052',\n",
              "       'Yale_0050628', 'Yale_0050574', 'UCLA_1_0051277', 'NYU_0050998',\n",
              "       'UCLA_2_0051294', 'USM_0050511', 'Leuven_1_0050695', 'NYU_0051026',\n",
              "       'UM_1_0050357', 'Trinity_0050268', 'SBL_0051556', 'NYU_0051075',\n",
              "       'SBL_0051574', 'UCLA_2_0051316', 'UM_1_0050368', 'SDSU_0050190',\n",
              "       'UM_1_0050351', 'SBL_0051562', 'Leuven_1_0050686',\n",
              "       'Stanford_0051173', 'UCLA_2_0051298', 'UM_1_0050329',\n",
              "       'Trinity_0050267', 'Pitt_0050028', 'UM_1_0050352', 'UM_1_0050373',\n",
              "       'SDSU_0050199', 'CMU_b_0050655', 'Trinity_0051138',\n",
              "       'Leuven_2_0050748', 'USM_0050490', 'Stanford_0051175',\n",
              "       'CMU_a_0050656', 'OHSU_0050163', 'UCLA_1_0051211',\n",
              "       'UCLA_1_0051257', 'NYU_0050958', 'NYU_0051152', 'NYU_0051066',\n",
              "       'UM_2_0050426', 'MaxMun_c_0051344', 'NYU_0050986',\n",
              "       'Trinity_0050255', 'OHSU_0050147', 'NYU_0051055',\n",
              "       'Leuven_1_0050682', 'SDSU_0050185', 'MaxMun_c_0051339',\n",
              "       'Leuven_1_0050683', 'NYU_0051053', 'UM_2_0050428', 'USM_0050486',\n",
              "       'NYU_0051113', 'UM_1_0050275', 'MaxMun_c_0051335', 'KKI_0050777',\n",
              "       'Yale_0050605', 'MaxMun_d_0051330', 'UCLA_1_0051209',\n",
              "       'UM_2_0050422', 'UM_2_0050427', 'UCLA_2_0051315',\n",
              "       'Trinity_0050250', 'USM_0050446', 'UM_1_0050337', 'USM_0050524',\n",
              "       'MaxMun_c_0051328', 'Pitt_0050055', 'NYU_0050979',\n",
              "       'Caltech_0051469', 'OHSU_0050142', 'MaxMun_a_0051370',\n",
              "       'UCLA_1_0051225', 'Pitt_0050029', 'Stanford_0051162',\n",
              "       'KKI_0050789', 'UM_1_0050375', 'NYU_0051093', 'Yale_0050604',\n",
              "       'Leuven_1_0050707', 'SDSU_0050196', 'Stanford_0051171',\n",
              "       'UCLA_1_0051249', 'Yale_0050606', 'CMU_b_0050643',\n",
              "       'UCLA_2_0051309', 'MaxMun_a_0051318', 'Stanford_0051184',\n",
              "       'MaxMun_d_0051329', 'UM_1_0050338', 'KKI_0050780', 'NYU_0051019',\n",
              "       'Yale_0050562', 'UM_1_0050326', 'Leuven_1_0050710', 'NYU_0051080',\n",
              "       'KKI_0050801', 'Caltech_0051493', 'SBL_0051578', 'Olin_0050136',\n",
              "       'UM_1_0050344', 'UM_1_0050289', 'NYU_0050994', 'Caltech_0051489',\n",
              "       'UM_1_0050306', 'Leuven_2_0050740', 'UCLA_1_0051250',\n",
              "       'KKI_0050778', 'MaxMun_a_0051362', 'Caltech_0051457',\n",
              "       'MaxMun_b_0051323', 'SBL_0051585', 'Pitt_0050039', 'UM_1_0050312',\n",
              "       'UM_1_0050284', 'USM_0050521', 'MaxMun_c_0051341',\n",
              "       'Trinity_0050234', 'NYU_0051065', 'NYU_0051061', 'UM_2_0050397',\n",
              "       'NYU_0051101', 'UCLA_1_0051234', 'SDSU_0050209', 'Yale_0050625',\n",
              "       'NYU_0051069', 'KKI_0050790', 'MaxMun_b_0051324', 'USM_0050439',\n",
              "       'UM_1_0050370', 'UCLA_1_0051268', 'NYU_0051040', 'UM_1_0050333',\n",
              "       'UM_1_0050365', 'UCLA_1_0051251', 'SBL_0051566', 'Caltech_0051484',\n",
              "       'OHSU_0050162', 'UM_1_0050372', 'USM_0050448', 'Pitt_0050057',\n",
              "       'SBL_0051561', 'MaxMun_d_0051360', 'Olin_0050105',\n",
              "       'UCLA_1_0051241', 'Leuven_1_0050704', 'Pitt_0050033',\n",
              "       'NYU_0050976', 'Yale_0050573', 'Leuven_1_0050705', 'Pitt_0050031',\n",
              "       'NYU_0051126', 'Leuven_1_0050693', 'SDSU_0050192', 'UM_1_0050358',\n",
              "       'SDSU_0050203', 'NYU_0051028', 'NYU_0050993', 'SDSU_0050188',\n",
              "       'UCLA_1_0051210', 'KKI_0050774', 'Yale_0050576', 'Trinity_0050236',\n",
              "       'UCLA_1_0051240', 'Leuven_2_0050757', 'NYU_0051027',\n",
              "       'Olin_0050111', 'UM_1_0050354', 'USM_0050455', 'Stanford_0051174',\n",
              "       'NYU_0050988', 'Pitt_0050019', 'UM_1_0050283', 'UCLA_1_0051218',\n",
              "       'UM_1_0050335', 'NYU_0051062', 'Pitt_0050017', 'NYU_0051151',\n",
              "       'MaxMun_d_0051358', 'Trinity_0050232', 'NYU_0050964',\n",
              "       'Pitt_0050003', 'Stanford_0051170', 'NYU_0051049', 'UM_1_0050281',\n",
              "       'KKI_0050772', 'UM_2_0050385', 'NYU_0051083', 'Trinity_0050253',\n",
              "       'Caltech_0051473', 'Caltech_0051458', 'Olin_0050115',\n",
              "       'Pitt_0050006', 'Leuven_2_0050753', 'NYU_0050969', 'UM_1_0050356',\n",
              "       'USM_0050501', 'Stanford_0051164', 'NYU_0051017',\n",
              "       'MaxMun_d_0051354', 'KKI_0050800', 'SDSU_0050183',\n",
              "       'UCLA_1_0051248', 'SBL_0051584', 'NYU_0051121', 'NYU_0051086',\n",
              "       'NYU_0051036', 'Stanford_0051186', 'Leuven_2_0050742',\n",
              "       'UM_1_0050290', 'USM_0050518', 'Yale_0050551', 'Leuven_2_0050736',\n",
              "       'UM_1_0050336', 'Pitt_0050036', 'KKI_0050817', 'NYU_0051100',\n",
              "       'UCLA_2_0051305', 'NYU_0051090', 'UM_1_0050349', 'NYU_0051159',\n",
              "       'KKI_0050795', 'NYU_0050954', 'NYU_0050983', 'UM_1_0050315',\n",
              "       'Leuven_2_0050728', 'NYU_0051011', 'Pitt_0050010',\n",
              "       'Caltech_0051485', 'UCLA_1_0051253', 'SBL_0051570', 'Pitt_0050014',\n",
              "       'SBL_0051563', 'Olin_0050135', 'OHSU_0050152', 'SDSU_0050195',\n",
              "       'UCLA_1_0051236', 'Yale_0050608', 'Caltech_0051456', 'USM_0050443',\n",
              "       'NYU_0051127', 'CMU_b_0050652', 'UM_1_0050280', 'NYU_0051072',\n",
              "       'NYU_0051123', 'Pitt_0050050', 'UCLA_1_0051206', 'USM_0050494',\n",
              "       'UCLA_1_0051256', 'NYU_0051051', 'MaxMun_b_0051327', 'KKI_0050773',\n",
              "       'UM_1_0050318', 'UM_1_0050311', 'Yale_0050559', 'USM_0050445',\n",
              "       'Stanford_0051167', 'NYU_0051064', 'Yale_0050621', 'NYU_0051087',\n",
              "       'Pitt_0050060', 'UM_1_0050350', 'Pitt_0050030', 'Leuven_1_0050685',\n",
              "       'NYU_0051050', 'UM_1_0050360', 'NYU_0051079', 'Olin_0050110',\n",
              "       'UCLA_1_0051269', 'Trinity_0050249', 'UM_1_0050305', 'NYU_0051068',\n",
              "       'UCLA_1_0051222', 'Trinity_0051136', 'UM_1_0050342',\n",
              "       'Pitt_0050049', 'UM_1_0050367', 'UCLA_1_0051255',\n",
              "       'MaxMun_d_0051331', 'Stanford_0051188', 'SBL_0051565',\n",
              "       'Olin_0050118', 'Leuven_2_0050750', 'KKI_0050781', 'KKI_0050785',\n",
              "       'MaxMun_a_0051607', 'UM_1_0050287', 'OHSU_0050143',\n",
              "       'UCLA_1_0051230', 'SBL_0051575', 'KKI_0050825', 'USM_0050532',\n",
              "       'USM_0050491', 'UM_2_0050425', 'Caltech_0051470',\n",
              "       'MaxMun_c_0051342', 'Leuven_1_0050708', 'Olin_0050120',\n",
              "       'SBL_0051572', 'Caltech_0051477', 'UM_2_0050383', 'Olin_0050133',\n",
              "       'USM_0050470', 'USM_0050507', 'CMU_a_0050665', 'Caltech_0051460',\n",
              "       'UCLA_1_0051272', 'OHSU_0050169', 'MaxMun_d_0051351',\n",
              "       'UM_1_0050294', 'UM_2_0050411', 'Stanford_0051181',\n",
              "       'Caltech_0051482', 'UM_1_0050278', 'USM_0050477', 'NYU_0050965',\n",
              "       'MaxMun_c_0051346'], dtype=object)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.FILE_ID.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbuwA6QQGHAe"
      },
      "source": [
        "The above variables are not unique so those are not going to add too much value to are dataset.\n",
        "\n",
        "So we are going to remove:\n",
        "\n",
        "*`FILE_ID`\n",
        "\n",
        "*`SITE_ID`\n",
        "\n",
        "*`Unnamed: 0`\n",
        "\n",
        "An then we are going to made MICE imputation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VdYDhLxKGzHj",
        "outputId": "fd081964-6fa5-4ec6-df4a-340a7ca84163"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bff7f9c6-cbbc-4566-a910-652adb566a9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SEX</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>subject</th>\n",
              "      <th>X</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "      <th>qc_anat_rater_2_fail</th>\n",
              "      <th>qc_anat_rater_2_maybe</th>\n",
              "      <th>qc_rater_1_fail</th>\n",
              "      <th>qc_rater_1_maybe</th>\n",
              "      <th>qc_func_rater_3_fail</th>\n",
              "      <th>qc_anat_rater_3_fail</th>\n",
              "      <th>qc_func_rater_2_fail</th>\n",
              "      <th>qc_func_rater_2_maybe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>2</td>\n",
              "      <td>51131</td>\n",
              "      <td>815</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>2</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>50237</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>2</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>51185</td>\n",
              "      <td>864</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>1</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>669</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>2</td>\n",
              "      <td>50653</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>50653</td>\n",
              "      <td>509</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>110.0</td>\n",
              "      <td>25.763782</td>\n",
              "      <td>0.565347</td>\n",
              "      <td>0.497512</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.039528</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>0.004377</td>\n",
              "      <td>1.137542</td>\n",
              "      <td>1.871921</td>\n",
              "      <td>79.216368</td>\n",
              "      <td>0.046415</td>\n",
              "      <td>0.101390</td>\n",
              "      <td>3.282660</td>\n",
              "      <td>7.616887</td>\n",
              "      <td>2.854406</td>\n",
              "      <td>12.592915</td>\n",
              "      <td>1</td>\n",
              "      <td>51357</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>51357</td>\n",
              "      <td>1026</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>8.450562</td>\n",
              "      <td>0.480033</td>\n",
              "      <td>46.766169</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.220653</td>\n",
              "      <td>0.005024</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>1.107504</td>\n",
              "      <td>1.995363</td>\n",
              "      <td>111.161146</td>\n",
              "      <td>0.025558</td>\n",
              "      <td>0.047992</td>\n",
              "      <td>2.911150</td>\n",
              "      <td>14.831974</td>\n",
              "      <td>1.436278</td>\n",
              "      <td>5.258132</td>\n",
              "      <td>2</td>\n",
              "      <td>51569</td>\n",
              "      <td>1</td>\n",
              "      <td>36.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>51569</td>\n",
              "      <td>1094</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>114.0</td>\n",
              "      <td>10.065393</td>\n",
              "      <td>0.509945</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.045803</td>\n",
              "      <td>0.015515</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>0.935325</td>\n",
              "      <td>1.811479</td>\n",
              "      <td>111.912491</td>\n",
              "      <td>-0.000797</td>\n",
              "      <td>0.061024</td>\n",
              "      <td>3.777362</td>\n",
              "      <td>90.430431</td>\n",
              "      <td>0.492807</td>\n",
              "      <td>8.071939</td>\n",
              "      <td>1</td>\n",
              "      <td>51153</td>\n",
              "      <td>1</td>\n",
              "      <td>26.1700</td>\n",
              "      <td>2</td>\n",
              "      <td>51153</td>\n",
              "      <td>834</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.573468</td>\n",
              "      <td>0.490547</td>\n",
              "      <td>30.845771</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.160136</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>1.178015</td>\n",
              "      <td>1.961812</td>\n",
              "      <td>101.314198</td>\n",
              "      <td>0.036961</td>\n",
              "      <td>0.130985</td>\n",
              "      <td>3.146340</td>\n",
              "      <td>2.540405</td>\n",
              "      <td>1.487330</td>\n",
              "      <td>2.940238</td>\n",
              "      <td>2</td>\n",
              "      <td>51580</td>\n",
              "      <td>1</td>\n",
              "      <td>42.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>51580</td>\n",
              "      <td>1105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>109.0</td>\n",
              "      <td>22.997706</td>\n",
              "      <td>0.514500</td>\n",
              "      <td>44.518272</td>\n",
              "      <td>134.0</td>\n",
              "      <td>0.245952</td>\n",
              "      <td>0.020060</td>\n",
              "      <td>0.010103</td>\n",
              "      <td>1.168608</td>\n",
              "      <td>2.492507</td>\n",
              "      <td>86.057649</td>\n",
              "      <td>0.025435</td>\n",
              "      <td>0.001943</td>\n",
              "      <td>3.090838</td>\n",
              "      <td>692.822630</td>\n",
              "      <td>0.416458</td>\n",
              "      <td>11.080846</td>\n",
              "      <td>1</td>\n",
              "      <td>50316</td>\n",
              "      <td>1</td>\n",
              "      <td>11.8000</td>\n",
              "      <td>1</td>\n",
              "      <td>50316</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bff7f9c6-cbbc-4566-a910-652adb566a9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bff7f9c6-cbbc-4566-a910-652adb566a9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bff7f9c6-cbbc-4566-a910-652adb566a9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      FIQ   anat_snr  func_efc  func_perc_fd  func_num_fd  func_mean_fd  \\\n",
              "0   119.0  12.866070  0.534295      1.104972          2.0      0.032827   \n",
              "1   118.0  10.833468  0.428382      4.635762          7.0      0.078301   \n",
              "2   119.0   9.159445  0.555808     28.630705         69.0      0.181608   \n",
              "3   142.0  10.456115  0.485962      0.552486          1.0      0.030118   \n",
              "4   134.0  68.951286  0.585246     34.854772         84.0      0.187709   \n",
              "5   110.0  25.763782  0.565347      0.497512          1.0      0.039528   \n",
              "6 -9999.0   8.450562  0.480033     46.766169         94.0      0.220653   \n",
              "7   114.0  10.065393  0.509945      1.104972          2.0      0.045803   \n",
              "8 -9999.0   4.573468  0.490547     30.845771         62.0      0.160136   \n",
              "9   109.0  22.997706  0.514500     44.518272        134.0      0.245952   \n",
              "\n",
              "   func_quality  func_outlier  func_dvars  func_fwhm   func_fber  func_gsr  \\\n",
              "0      0.014129      0.006217    1.018414   1.765660   78.296410 -0.001329   \n",
              "1      0.008713      0.002349    1.064568   1.955725  137.815548  0.010631   \n",
              "2      0.007197      0.007001    1.302140   2.772167   59.038003  0.036467   \n",
              "3      0.011202      0.006253    0.938920   2.057008  142.036348 -0.010039   \n",
              "4      0.007730      0.001147    1.156320   1.680437   88.589366  0.079297   \n",
              "5      0.008172      0.004377    1.137542   1.871921   79.216368  0.046415   \n",
              "6      0.005024      0.000660    1.107504   1.995363  111.161146  0.025558   \n",
              "7      0.015515      0.005884    0.935325   1.811479  111.912491 -0.000797   \n",
              "8      0.005715      0.001758    1.178015   1.961812  101.314198  0.036961   \n",
              "9      0.020060      0.010103    1.168608   2.492507   86.057649  0.025435   \n",
              "\n",
              "   anat_qi1  anat_fwhm   anat_fber   anat_efc   anat_cnr  EYE_STATUS_AT_SCAN  \\\n",
              "0  0.067764   3.509732   89.045514   0.616051  10.674176                   1   \n",
              "1  0.075520   4.425869   11.113986   1.674990   7.004004                   2   \n",
              "2  0.241977   2.824676    0.029120  14.838937   9.180373                   2   \n",
              "3  0.055056   3.220905   78.004528   0.517920   9.087565                   1   \n",
              "4  0.058810   3.423460   32.931736   4.167438  26.045369                   2   \n",
              "5  0.101390   3.282660    7.616887   2.854406  12.592915                   1   \n",
              "6  0.047992   2.911150   14.831974   1.436278   5.258132                   2   \n",
              "7  0.061024   3.777362   90.430431   0.492807   8.071939                   1   \n",
              "8  0.130985   3.146340    2.540405   1.487330   2.940238                   2   \n",
              "9  0.001943   3.090838  692.822630   0.416458  11.080846                   1   \n",
              "\n",
              "   SUB_ID  SEX  AGE_AT_SCAN  DX_GROUP  subject     X  SUB_IN_SMP  \\\n",
              "0   51131    1      19.7300         2    51131   815           1   \n",
              "1   50237    1      21.4200         1    50237   163           1   \n",
              "2   51185    1       8.2464         2    51185   864           1   \n",
              "3   50978    1       9.5800         1    50978   669           0   \n",
              "4   50653    1      30.0000         1    50653   509           0   \n",
              "5   51357    1      11.0000         2    51357  1026           1   \n",
              "6   51569    1      36.0000         2    51569  1094           0   \n",
              "7   51153    1      26.1700         2    51153   834           1   \n",
              "8   51580    1      42.0000         1    51580  1105           0   \n",
              "9   50316    1      11.8000         1    50316   240           1   \n",
              "\n",
              "   qc_anat_rater_2_fail  qc_anat_rater_2_maybe  qc_rater_1_fail  \\\n",
              "0                     0                      0                0   \n",
              "1                     0                      0                0   \n",
              "2                     0                      1                0   \n",
              "3                     0                      0                0   \n",
              "4                     0                      0                1   \n",
              "5                     0                      1                0   \n",
              "6                     0                      0                0   \n",
              "7                     0                      0                0   \n",
              "8                     0                      0                0   \n",
              "9                     0                      1                0   \n",
              "\n",
              "   qc_rater_1_maybe  qc_func_rater_3_fail  qc_anat_rater_3_fail  \\\n",
              "0                 0                     0                     0   \n",
              "1                 0                     0                     0   \n",
              "2                 0                     0                     0   \n",
              "3                 0                     0                     0   \n",
              "4                 0                     0                     0   \n",
              "5                 0                     0                     0   \n",
              "6                 0                     0                     0   \n",
              "7                 0                     0                     0   \n",
              "8                 0                     0                     0   \n",
              "9                 0                     0                     1   \n",
              "\n",
              "   qc_func_rater_2_fail  qc_func_rater_2_maybe  \n",
              "0                     0                      0  \n",
              "1                     0                      0  \n",
              "2                     0                      0  \n",
              "3                     0                      0  \n",
              "4                     1                      0  \n",
              "5                     0                      1  \n",
              "6                     0                      1  \n",
              "7                     0                      1  \n",
              "8                     0                      1  \n",
              "9                     0                      0  "
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1= df_dummies.drop(['Unnamed: 0','FILE_ID','SITE_ID'], axis=1)#removing variables with no more value\n",
        "df_1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "q2Tf4BeQHO9K",
        "outputId": "38638a40-2840-49b4-c005-febf97e443ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c38faf85-71b4-4e48-bb04-8b3596207021\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>0.014129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.008713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.007197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>0.011202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.007730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>103.0</td>\n",
              "      <td>4.605309</td>\n",
              "      <td>-7.639415</td>\n",
              "      <td>234.970752</td>\n",
              "      <td>3.724990</td>\n",
              "      <td>0.092700</td>\n",
              "      <td>254.347101</td>\n",
              "      <td>1.010008</td>\n",
              "      <td>0.490541</td>\n",
              "      <td>95.257385</td>\n",
              "      <td>2.065640</td>\n",
              "      <td>0.038512</td>\n",
              "      <td>0.045737</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>1.324503</td>\n",
              "      <td>0.003968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>107.5</td>\n",
              "      <td>10.985865</td>\n",
              "      <td>9.963586</td>\n",
              "      <td>0.265646</td>\n",
              "      <td>2.608884</td>\n",
              "      <td>0.002402</td>\n",
              "      <td>18.573171</td>\n",
              "      <td>1.023363</td>\n",
              "      <td>0.586351</td>\n",
              "      <td>65.761519</td>\n",
              "      <td>2.568014</td>\n",
              "      <td>0.061120</td>\n",
              "      <td>0.191137</td>\n",
              "      <td>0.006191</td>\n",
              "      <td>24.584718</td>\n",
              "      <td>0.026467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>92.0</td>\n",
              "      <td>13.311842</td>\n",
              "      <td>2.316845</td>\n",
              "      <td>5.028586</td>\n",
              "      <td>4.878726</td>\n",
              "      <td>0.042362</td>\n",
              "      <td>20.048159</td>\n",
              "      <td>1.053701</td>\n",
              "      <td>0.519434</td>\n",
              "      <td>70.936407</td>\n",
              "      <td>1.892772</td>\n",
              "      <td>0.032019</td>\n",
              "      <td>0.087332</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>8.298755</td>\n",
              "      <td>0.020164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>132.0</td>\n",
              "      <td>11.674108</td>\n",
              "      <td>0.454438</td>\n",
              "      <td>140.617266</td>\n",
              "      <td>3.485226</td>\n",
              "      <td>0.088045</td>\n",
              "      <td>12.139245</td>\n",
              "      <td>0.895435</td>\n",
              "      <td>0.501172</td>\n",
              "      <td>134.300311</td>\n",
              "      <td>1.964289</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>0.111081</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>9.944751</td>\n",
              "      <td>0.020851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>118.0</td>\n",
              "      <td>8.771666</td>\n",
              "      <td>2.272357</td>\n",
              "      <td>7.669491</td>\n",
              "      <td>3.590950</td>\n",
              "      <td>0.080716</td>\n",
              "      <td>19.711215</td>\n",
              "      <td>1.014639</td>\n",
              "      <td>0.602443</td>\n",
              "      <td>48.866041</td>\n",
              "      <td>1.739131</td>\n",
              "      <td>0.052086</td>\n",
              "      <td>0.061895</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>3.305785</td>\n",
              "      <td>0.010230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38faf85-71b4-4e48-bb04-8b3596207021')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c38faf85-71b4-4e48-bb04-8b3596207021 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c38faf85-71b4-4e48-bb04-8b3596207021');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       FIQ   anat_cnr   anat_efc   anat_fber  anat_fwhm  anat_qi1    anat_snr  \\\n",
              "0    119.0  10.674176   0.616051   89.045514   3.509732  0.067764   12.866070   \n",
              "1    118.0   7.004004   1.674990   11.113986   4.425869  0.075520   10.833468   \n",
              "2    119.0   9.180373  14.838937    0.029120   2.824676  0.241977    9.159445   \n",
              "3    142.0   9.087565   0.517920   78.004528   3.220905  0.055056   10.456115   \n",
              "4    134.0  26.045369   4.167438   32.931736   3.423460  0.058810   68.951286   \n",
              "..     ...        ...        ...         ...        ...       ...         ...   \n",
              "926  103.0   4.605309  -7.639415  234.970752   3.724990  0.092700  254.347101   \n",
              "927  107.5  10.985865   9.963586    0.265646   2.608884  0.002402   18.573171   \n",
              "928   92.0  13.311842   2.316845    5.028586   4.878726  0.042362   20.048159   \n",
              "929  132.0  11.674108   0.454438  140.617266   3.485226  0.088045   12.139245   \n",
              "930  118.0   8.771666   2.272357    7.669491   3.590950  0.080716   19.711215   \n",
              "\n",
              "     func_dvars  func_efc   func_fber  func_fwhm  func_gsr  func_mean_fd  \\\n",
              "0      1.018414  0.534295   78.296410   1.765660 -0.001329      0.032827   \n",
              "1      1.064568  0.428382  137.815548   1.955725  0.010631      0.078301   \n",
              "2      1.302140  0.555808   59.038003   2.772167  0.036467      0.181608   \n",
              "3      0.938920  0.485962  142.036348   2.057008 -0.010039      0.030118   \n",
              "4      1.156320  0.585246   88.589366   1.680437  0.079297      0.187709   \n",
              "..          ...       ...         ...        ...       ...           ...   \n",
              "926    1.010008  0.490541   95.257385   2.065640  0.038512      0.045737   \n",
              "927    1.023363  0.586351   65.761519   2.568014  0.061120      0.191137   \n",
              "928    1.053701  0.519434   70.936407   1.892772  0.032019      0.087332   \n",
              "929    0.895435  0.501172  134.300311   1.964289 -0.000354      0.111081   \n",
              "930    1.014639  0.602443   48.866041   1.739131  0.052086      0.061895   \n",
              "\n",
              "     func_outlier  func_perc_fd  func_quality  \n",
              "0        0.006217      1.104972      0.014129  \n",
              "1        0.002349      4.635762      0.008713  \n",
              "2        0.007001     28.630705      0.007197  \n",
              "3        0.006253      0.552486      0.011202  \n",
              "4        0.001147     34.854772      0.007730  \n",
              "..            ...           ...           ...  \n",
              "926      0.000624      1.324503      0.003968  \n",
              "927      0.006191     24.584718      0.026467  \n",
              "928      0.002621      8.298755      0.020164  \n",
              "929      0.006488      9.944751      0.020851  \n",
              "930      0.001108      3.305785      0.010230  \n",
              "\n",
              "[931 rows x 16 columns]"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#First we are going to impute the float data with MICE mean and then the categorical value with the most frequent values\n",
        "df_float_missing= df_1[df_1.loc[:,:'anat_cnr'].columns.difference(['func_num_fd'])]\n",
        "df_float_missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "2f6e3DaijMLX",
        "outputId": "2f0b2b70-241c-42c8-ec8b-39fb7dd30f99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "msno.bar(df_float_missing, figsize=(12, 6), fontsize=12, color='steelblue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1GARXGndu42"
      },
      "source": [
        "The dataset still contains missing values, and to address this issue, we will apply Multiple Imputation by Chained Equations (MICE) imputation, as mentioned in the article. After filtering the data based on our criteria, we will proceed with the MICE imputation to handle the remaining missing values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsezK5mElSON",
        "outputId": "b42b0e72-54d6-493b-c692-fd67a03d4fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 931 entries, 0 to 930\n",
            "Data columns (total 16 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   FIQ           905 non-null    float64\n",
            " 1   anat_cnr      930 non-null    float64\n",
            " 2   anat_efc      930 non-null    float64\n",
            " 3   anat_fber     930 non-null    float64\n",
            " 4   anat_fwhm     930 non-null    float64\n",
            " 5   anat_qi1      930 non-null    float64\n",
            " 6   anat_snr      930 non-null    float64\n",
            " 7   func_dvars    930 non-null    float64\n",
            " 8   func_efc      930 non-null    float64\n",
            " 9   func_fber     930 non-null    float64\n",
            " 10  func_fwhm     930 non-null    float64\n",
            " 11  func_gsr      930 non-null    float64\n",
            " 12  func_mean_fd  930 non-null    float64\n",
            " 13  func_outlier  930 non-null    float64\n",
            " 14  func_perc_fd  930 non-null    float64\n",
            " 15  func_quality  930 non-null    float64\n",
            "dtypes: float64(16)\n",
            "memory usage: 116.5 KB\n"
          ]
        }
      ],
      "source": [
        "df_float_missing.info()# Now we can see the type of the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY0OtC-L-h77"
      },
      "source": [
        "# MICE IMPUTATION\n",
        "\n",
        "STEPS:\n",
        "\n",
        "\n",
        "1. Basically take the variable that contains missing values as a response ‘Y’ and other variables as predictors ‘X’.\n",
        "\n",
        "2. Build a model with rows where Y is not missing.\n",
        "\n",
        "3. Then predict the missing observations.\n",
        "\n",
        "We do this multiple times by doing random draws of the data and taking the mean of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0coguU0RqDcf"
      },
      "outputs": [],
      "source": [
        "# need to enable iterative imputer explicitly since its still experimental\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arT1vvvVK7pZ"
      },
      "outputs": [],
      "source": [
        "miss_rows = df_float_missing.isna().any(axis = 1)\n",
        "df_miss = df_float_missing[miss_rows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHqxcjAL_yd7",
        "outputId": "2b2b9be0-5fb2-49e9-d943-8ffc4fea8a0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27, 16)"
            ]
          },
          "execution_count": 262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_miss.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFGS9JjqHUHy",
        "outputId": "a61f7cdc-cb2d-403a-97c3-a2434262da54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  119. ,   118. ,   142. ,   134. ,   110. , -9999. ,   114. ,\n",
              "         109. ,    98. ,   131. ,   113. ,   103. ,    75. ,     nan,\n",
              "         123. ,   116. ,    93.5,   100. ,   113.5,   148. ,   104. ,\n",
              "         106. ,    89. ,    73. ,    93. ,   101. ,   127. ,   117. ,\n",
              "         126. ,    97. ,   112. ,   138. ,   136. ,   105. ,   120. ,\n",
              "         111.5,   111. ,   102. ,    86. ,    76. ,    91. ,    69.6,\n",
              "         115. ,   122. ,   106.5,    88. ,   132. ,   129. ,    83. ,\n",
              "         128. ,    98.5,   108. ,    95.5,   141. ,   137. ,   121. ,\n",
              "         121.5,    90. ,    78. ,    72. ,   107. ,   125. ,    95. ,\n",
              "         115.2,   139. ,   107.6,    78.5,   103.5,    99. ,    80. ,\n",
              "         124. ,    92. ,    94. ,    96. ,    77. ,    92.5,    87.5,\n",
              "         107.5,    79. ,    85. ,   135. ,    87. ,   108.5,    96.5,\n",
              "         146. ,   130. ,   104.5,   129.5,   124.5,   110.5,   146.5,\n",
              "         112.5,   115.5,    77.2,    89.5,    84. ,   127.5,   133.5,\n",
              "         120.5,   105.7,    69. ,    97.5,    82. ,   133. ,   114.5,\n",
              "          81. ,   140. ,   118.5,   118.7,   123.5,    41. ,   100.5,\n",
              "         144. ,    99.5,    65. ,   147.5,   109.5,   125.5])"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_float_missing['FIQ'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "lsyIeKpsGNgC",
        "outputId": "dbf5cd70-43dc-4889-d937-67027b9e9d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.boxplot(df_float_missing['FIQ'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AE2SKCy1HpLq",
        "outputId": "503692e4-c281-435e-c257-443ed935f770"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-002dbc01-1ddb-4ffc-b644-d820cf426e73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>5.258132</td>\n",
              "      <td>1.436278</td>\n",
              "      <td>14.831974</td>\n",
              "      <td>2.911150</td>\n",
              "      <td>0.047992</td>\n",
              "      <td>8.450562</td>\n",
              "      <td>1.107504</td>\n",
              "      <td>0.480033</td>\n",
              "      <td>111.161146</td>\n",
              "      <td>1.995363</td>\n",
              "      <td>0.025558</td>\n",
              "      <td>0.220653</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>46.766169</td>\n",
              "      <td>0.005024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>2.940238</td>\n",
              "      <td>1.487330</td>\n",
              "      <td>2.540405</td>\n",
              "      <td>3.146340</td>\n",
              "      <td>0.130985</td>\n",
              "      <td>4.573468</td>\n",
              "      <td>1.178015</td>\n",
              "      <td>0.490547</td>\n",
              "      <td>101.314198</td>\n",
              "      <td>1.961812</td>\n",
              "      <td>0.036961</td>\n",
              "      <td>0.160136</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>30.845771</td>\n",
              "      <td>0.005715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>5.389460</td>\n",
              "      <td>1.413071</td>\n",
              "      <td>7.826634</td>\n",
              "      <td>3.236620</td>\n",
              "      <td>0.061095</td>\n",
              "      <td>7.141211</td>\n",
              "      <td>1.143517</td>\n",
              "      <td>0.495382</td>\n",
              "      <td>80.000195</td>\n",
              "      <td>1.951576</td>\n",
              "      <td>0.030638</td>\n",
              "      <td>0.094722</td>\n",
              "      <td>0.001331</td>\n",
              "      <td>6.965174</td>\n",
              "      <td>0.004288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>8.382919</td>\n",
              "      <td>2.195348</td>\n",
              "      <td>7.619788</td>\n",
              "      <td>3.395290</td>\n",
              "      <td>0.154025</td>\n",
              "      <td>14.773005</td>\n",
              "      <td>1.317319</td>\n",
              "      <td>0.480779</td>\n",
              "      <td>86.052468</td>\n",
              "      <td>1.936867</td>\n",
              "      <td>0.026142</td>\n",
              "      <td>0.022373</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>6.734932</td>\n",
              "      <td>11.565194</td>\n",
              "      <td>6.474996</td>\n",
              "      <td>2.704378</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>11.720422</td>\n",
              "      <td>1.127170</td>\n",
              "      <td>0.540687</td>\n",
              "      <td>84.153029</td>\n",
              "      <td>2.328669</td>\n",
              "      <td>0.027709</td>\n",
              "      <td>0.032230</td>\n",
              "      <td>0.001020</td>\n",
              "      <td>0.332226</td>\n",
              "      <td>0.007990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.577269</td>\n",
              "      <td>1.520595</td>\n",
              "      <td>7.211705</td>\n",
              "      <td>2.910720</td>\n",
              "      <td>0.060916</td>\n",
              "      <td>6.814600</td>\n",
              "      <td>1.138462</td>\n",
              "      <td>0.482650</td>\n",
              "      <td>104.150354</td>\n",
              "      <td>2.080765</td>\n",
              "      <td>0.035488</td>\n",
              "      <td>0.161788</td>\n",
              "      <td>0.000728</td>\n",
              "      <td>26.865672</td>\n",
              "      <td>0.010123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.950808</td>\n",
              "      <td>1.671033</td>\n",
              "      <td>2.804149</td>\n",
              "      <td>3.553380</td>\n",
              "      <td>0.088266</td>\n",
              "      <td>6.155381</td>\n",
              "      <td>1.163657</td>\n",
              "      <td>0.482051</td>\n",
              "      <td>124.373251</td>\n",
              "      <td>2.048877</td>\n",
              "      <td>0.022641</td>\n",
              "      <td>0.199617</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>39.303483</td>\n",
              "      <td>0.006747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.221312</td>\n",
              "      <td>1.426890</td>\n",
              "      <td>7.857000</td>\n",
              "      <td>2.988560</td>\n",
              "      <td>0.066745</td>\n",
              "      <td>6.432693</td>\n",
              "      <td>1.216343</td>\n",
              "      <td>0.495054</td>\n",
              "      <td>88.843272</td>\n",
              "      <td>1.860183</td>\n",
              "      <td>0.030739</td>\n",
              "      <td>0.130655</td>\n",
              "      <td>0.003248</td>\n",
              "      <td>14.925373</td>\n",
              "      <td>0.008621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>9.894660</td>\n",
              "      <td>1.815002</td>\n",
              "      <td>16.819808</td>\n",
              "      <td>3.473960</td>\n",
              "      <td>0.070962</td>\n",
              "      <td>15.448800</td>\n",
              "      <td>1.035931</td>\n",
              "      <td>0.548127</td>\n",
              "      <td>78.684485</td>\n",
              "      <td>1.849910</td>\n",
              "      <td>0.046890</td>\n",
              "      <td>0.083783</td>\n",
              "      <td>0.007047</td>\n",
              "      <td>0.947867</td>\n",
              "      <td>0.009904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.768935</td>\n",
              "      <td>1.601895</td>\n",
              "      <td>6.335901</td>\n",
              "      <td>2.893500</td>\n",
              "      <td>0.064087</td>\n",
              "      <td>7.342628</td>\n",
              "      <td>1.097789</td>\n",
              "      <td>0.487604</td>\n",
              "      <td>79.486838</td>\n",
              "      <td>1.918145</td>\n",
              "      <td>0.042990</td>\n",
              "      <td>0.171107</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>33.830846</td>\n",
              "      <td>0.007724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>2.687600</td>\n",
              "      <td>1.658664</td>\n",
              "      <td>2.607570</td>\n",
              "      <td>3.376190</td>\n",
              "      <td>0.122338</td>\n",
              "      <td>4.074631</td>\n",
              "      <td>1.190833</td>\n",
              "      <td>0.486656</td>\n",
              "      <td>109.718275</td>\n",
              "      <td>2.009262</td>\n",
              "      <td>0.041192</td>\n",
              "      <td>0.138318</td>\n",
              "      <td>0.000788</td>\n",
              "      <td>21.890547</td>\n",
              "      <td>0.006595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>9.006927</td>\n",
              "      <td>10.274673</td>\n",
              "      <td>15.763646</td>\n",
              "      <td>3.097040</td>\n",
              "      <td>0.004679</td>\n",
              "      <td>17.275741</td>\n",
              "      <td>1.049787</td>\n",
              "      <td>0.499136</td>\n",
              "      <td>77.083093</td>\n",
              "      <td>2.222115</td>\n",
              "      <td>0.029057</td>\n",
              "      <td>0.034014</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.863499</td>\n",
              "      <td>1.254731</td>\n",
              "      <td>6.722111</td>\n",
              "      <td>3.544610</td>\n",
              "      <td>0.085925</td>\n",
              "      <td>6.070108</td>\n",
              "      <td>1.145621</td>\n",
              "      <td>0.467642</td>\n",
              "      <td>118.887419</td>\n",
              "      <td>2.087152</td>\n",
              "      <td>0.026808</td>\n",
              "      <td>0.147701</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>26.865672</td>\n",
              "      <td>0.004944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>12.138727</td>\n",
              "      <td>1.450839</td>\n",
              "      <td>20.761660</td>\n",
              "      <td>3.565510</td>\n",
              "      <td>0.077548</td>\n",
              "      <td>17.801393</td>\n",
              "      <td>0.852250</td>\n",
              "      <td>0.453736</td>\n",
              "      <td>114.796411</td>\n",
              "      <td>1.940677</td>\n",
              "      <td>0.031111</td>\n",
              "      <td>0.079033</td>\n",
              "      <td>0.018740</td>\n",
              "      <td>3.317536</td>\n",
              "      <td>0.006492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.536205</td>\n",
              "      <td>1.433258</td>\n",
              "      <td>5.037868</td>\n",
              "      <td>3.277650</td>\n",
              "      <td>0.088665</td>\n",
              "      <td>5.492969</td>\n",
              "      <td>1.142243</td>\n",
              "      <td>0.465977</td>\n",
              "      <td>124.576568</td>\n",
              "      <td>1.919242</td>\n",
              "      <td>0.030054</td>\n",
              "      <td>0.142374</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>21.890547</td>\n",
              "      <td>0.005835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>11.705633</td>\n",
              "      <td>7.285355</td>\n",
              "      <td>3.812838</td>\n",
              "      <td>2.824575</td>\n",
              "      <td>0.001829</td>\n",
              "      <td>24.173951</td>\n",
              "      <td>0.999252</td>\n",
              "      <td>0.571828</td>\n",
              "      <td>53.651111</td>\n",
              "      <td>2.160952</td>\n",
              "      <td>0.046637</td>\n",
              "      <td>0.030265</td>\n",
              "      <td>0.000898</td>\n",
              "      <td>0.332226</td>\n",
              "      <td>0.014246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.580298</td>\n",
              "      <td>1.511072</td>\n",
              "      <td>8.336963</td>\n",
              "      <td>3.000720</td>\n",
              "      <td>0.060600</td>\n",
              "      <td>6.891173</td>\n",
              "      <td>1.179021</td>\n",
              "      <td>0.489111</td>\n",
              "      <td>92.033973</td>\n",
              "      <td>1.848336</td>\n",
              "      <td>0.037427</td>\n",
              "      <td>0.164435</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>29.850746</td>\n",
              "      <td>0.006930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.746960</td>\n",
              "      <td>0.997956</td>\n",
              "      <td>15.593540</td>\n",
              "      <td>2.885570</td>\n",
              "      <td>0.056971</td>\n",
              "      <td>7.349228</td>\n",
              "      <td>1.153679</td>\n",
              "      <td>0.469991</td>\n",
              "      <td>124.681411</td>\n",
              "      <td>1.899898</td>\n",
              "      <td>0.017776</td>\n",
              "      <td>0.271007</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>71.641791</td>\n",
              "      <td>0.007928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.438417</td>\n",
              "      <td>0.839520</td>\n",
              "      <td>9.140577</td>\n",
              "      <td>3.359410</td>\n",
              "      <td>0.099237</td>\n",
              "      <td>5.456160</td>\n",
              "      <td>1.204335</td>\n",
              "      <td>0.445782</td>\n",
              "      <td>205.468216</td>\n",
              "      <td>2.032735</td>\n",
              "      <td>0.019955</td>\n",
              "      <td>0.183134</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>34.328358</td>\n",
              "      <td>0.009129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.756250</td>\n",
              "      <td>1.089930</td>\n",
              "      <td>8.028431</td>\n",
              "      <td>3.398550</td>\n",
              "      <td>0.107655</td>\n",
              "      <td>5.249783</td>\n",
              "      <td>1.188214</td>\n",
              "      <td>0.494691</td>\n",
              "      <td>91.066212</td>\n",
              "      <td>1.828907</td>\n",
              "      <td>0.020957</td>\n",
              "      <td>0.334374</td>\n",
              "      <td>0.015621</td>\n",
              "      <td>31.840796</td>\n",
              "      <td>0.022776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>5.466269</td>\n",
              "      <td>1.044190</td>\n",
              "      <td>16.415246</td>\n",
              "      <td>3.046780</td>\n",
              "      <td>0.048442</td>\n",
              "      <td>7.804992</td>\n",
              "      <td>1.197003</td>\n",
              "      <td>0.477982</td>\n",
              "      <td>114.541675</td>\n",
              "      <td>2.016993</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.132729</td>\n",
              "      <td>0.001277</td>\n",
              "      <td>14.427861</td>\n",
              "      <td>0.005119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.322417</td>\n",
              "      <td>1.355895</td>\n",
              "      <td>5.447101</td>\n",
              "      <td>3.224120</td>\n",
              "      <td>0.085435</td>\n",
              "      <td>5.262363</td>\n",
              "      <td>1.158028</td>\n",
              "      <td>0.465215</td>\n",
              "      <td>115.298629</td>\n",
              "      <td>1.885277</td>\n",
              "      <td>0.020315</td>\n",
              "      <td>0.113176</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>9.452736</td>\n",
              "      <td>0.019403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>8.629715</td>\n",
              "      <td>2.425867</td>\n",
              "      <td>8.965462</td>\n",
              "      <td>3.450520</td>\n",
              "      <td>0.064947</td>\n",
              "      <td>20.285101</td>\n",
              "      <td>1.013861</td>\n",
              "      <td>0.606909</td>\n",
              "      <td>51.904953</td>\n",
              "      <td>1.822706</td>\n",
              "      <td>0.058184</td>\n",
              "      <td>0.147098</td>\n",
              "      <td>0.000789</td>\n",
              "      <td>21.890547</td>\n",
              "      <td>0.019480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>4.733237</td>\n",
              "      <td>1.521456</td>\n",
              "      <td>7.101676</td>\n",
              "      <td>3.233030</td>\n",
              "      <td>0.068319</td>\n",
              "      <td>7.195671</td>\n",
              "      <td>1.116740</td>\n",
              "      <td>0.472449</td>\n",
              "      <td>116.536981</td>\n",
              "      <td>1.943543</td>\n",
              "      <td>0.021309</td>\n",
              "      <td>0.136413</td>\n",
              "      <td>0.000944</td>\n",
              "      <td>22.388060</td>\n",
              "      <td>0.006209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>5.486405</td>\n",
              "      <td>1.277088</td>\n",
              "      <td>12.944733</td>\n",
              "      <td>2.826070</td>\n",
              "      <td>0.054069</td>\n",
              "      <td>7.810627</td>\n",
              "      <td>1.114646</td>\n",
              "      <td>0.511716</td>\n",
              "      <td>82.045288</td>\n",
              "      <td>1.968684</td>\n",
              "      <td>0.034365</td>\n",
              "      <td>0.124083</td>\n",
              "      <td>0.001948</td>\n",
              "      <td>15.920398</td>\n",
              "      <td>0.007119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>-77.900491</td>\n",
              "      <td>434.978330</td>\n",
              "      <td>4.091920</td>\n",
              "      <td>0.084651</td>\n",
              "      <td>0.026476</td>\n",
              "      <td>1.080351</td>\n",
              "      <td>0.517160</td>\n",
              "      <td>76.632240</td>\n",
              "      <td>2.017880</td>\n",
              "      <td>0.038054</td>\n",
              "      <td>0.057301</td>\n",
              "      <td>0.003345</td>\n",
              "      <td>3.973510</td>\n",
              "      <td>0.007524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>2.757735</td>\n",
              "      <td>1.073076</td>\n",
              "      <td>7.633618</td>\n",
              "      <td>3.309370</td>\n",
              "      <td>0.104817</td>\n",
              "      <td>4.516250</td>\n",
              "      <td>1.122410</td>\n",
              "      <td>0.486408</td>\n",
              "      <td>108.510115</td>\n",
              "      <td>2.064103</td>\n",
              "      <td>0.033177</td>\n",
              "      <td>0.140171</td>\n",
              "      <td>0.001508</td>\n",
              "      <td>18.407960</td>\n",
              "      <td>0.012669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.090007</td>\n",
              "      <td>0.399857</td>\n",
              "      <td>31.030144</td>\n",
              "      <td>3.228790</td>\n",
              "      <td>0.089614</td>\n",
              "      <td>4.947239</td>\n",
              "      <td>1.082660</td>\n",
              "      <td>0.471565</td>\n",
              "      <td>103.960263</td>\n",
              "      <td>1.986581</td>\n",
              "      <td>0.022805</td>\n",
              "      <td>0.119588</td>\n",
              "      <td>0.002412</td>\n",
              "      <td>9.950249</td>\n",
              "      <td>0.006920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>2.790305</td>\n",
              "      <td>1.174401</td>\n",
              "      <td>6.318626</td>\n",
              "      <td>3.343790</td>\n",
              "      <td>0.106030</td>\n",
              "      <td>4.606572</td>\n",
              "      <td>1.055674</td>\n",
              "      <td>0.506452</td>\n",
              "      <td>60.808040</td>\n",
              "      <td>1.907286</td>\n",
              "      <td>0.029264</td>\n",
              "      <td>0.127575</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>12.935323</td>\n",
              "      <td>0.008523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>7.231076</td>\n",
              "      <td>2.530636</td>\n",
              "      <td>7.117171</td>\n",
              "      <td>3.324940</td>\n",
              "      <td>0.091659</td>\n",
              "      <td>16.121489</td>\n",
              "      <td>0.985982</td>\n",
              "      <td>0.600982</td>\n",
              "      <td>61.296862</td>\n",
              "      <td>1.808763</td>\n",
              "      <td>0.055706</td>\n",
              "      <td>0.115698</td>\n",
              "      <td>0.003953</td>\n",
              "      <td>9.452736</td>\n",
              "      <td>0.017076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.102250</td>\n",
              "      <td>1.367696</td>\n",
              "      <td>5.106239</td>\n",
              "      <td>3.251950</td>\n",
              "      <td>0.092807</td>\n",
              "      <td>4.787800</td>\n",
              "      <td>1.152203</td>\n",
              "      <td>0.468724</td>\n",
              "      <td>122.397255</td>\n",
              "      <td>1.910385</td>\n",
              "      <td>0.025146</td>\n",
              "      <td>0.122904</td>\n",
              "      <td>0.000847</td>\n",
              "      <td>14.427861</td>\n",
              "      <td>0.005174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>5.794431</td>\n",
              "      <td>1.730441</td>\n",
              "      <td>7.783196</td>\n",
              "      <td>3.180180</td>\n",
              "      <td>0.060901</td>\n",
              "      <td>7.486296</td>\n",
              "      <td>1.110365</td>\n",
              "      <td>0.496913</td>\n",
              "      <td>130.969017</td>\n",
              "      <td>2.030166</td>\n",
              "      <td>0.034672</td>\n",
              "      <td>0.415470</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>75.621891</td>\n",
              "      <td>0.011393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>-9999.0</td>\n",
              "      <td>3.601109</td>\n",
              "      <td>1.264992</td>\n",
              "      <td>5.158230</td>\n",
              "      <td>3.239030</td>\n",
              "      <td>0.101655</td>\n",
              "      <td>5.069206</td>\n",
              "      <td>1.192050</td>\n",
              "      <td>0.472395</td>\n",
              "      <td>104.648364</td>\n",
              "      <td>2.027010</td>\n",
              "      <td>0.038234</td>\n",
              "      <td>0.126411</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>16.417910</td>\n",
              "      <td>0.006622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-002dbc01-1ddb-4ffc-b644-d820cf426e73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-002dbc01-1ddb-4ffc-b644-d820cf426e73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-002dbc01-1ddb-4ffc-b644-d820cf426e73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        FIQ   anat_cnr   anat_efc   anat_fber  anat_fwhm  anat_qi1   anat_snr  \\\n",
              "6   -9999.0   5.258132   1.436278   14.831974   2.911150  0.047992   8.450562   \n",
              "8   -9999.0   2.940238   1.487330    2.540405   3.146340  0.130985   4.573468   \n",
              "64  -9999.0   5.389460   1.413071    7.826634   3.236620  0.061095   7.141211   \n",
              "86  -9999.0   8.382919   2.195348    7.619788   3.395290  0.154025  14.773005   \n",
              "98  -9999.0   6.734932  11.565194    6.474996   2.704378  0.002896  11.720422   \n",
              "147 -9999.0   4.577269   1.520595    7.211705   2.910720  0.060916   6.814600   \n",
              "159 -9999.0   3.950808   1.671033    2.804149   3.553380  0.088266   6.155381   \n",
              "224 -9999.0   4.221312   1.426890    7.857000   2.988560  0.066745   6.432693   \n",
              "225 -9999.0   9.894660   1.815002   16.819808   3.473960  0.070962  15.448800   \n",
              "326 -9999.0   4.768935   1.601895    6.335901   2.893500  0.064087   7.342628   \n",
              "341 -9999.0   2.687600   1.658664    2.607570   3.376190  0.122338   4.074631   \n",
              "452 -9999.0   9.006927  10.274673   15.763646   3.097040  0.004679  17.275741   \n",
              "497 -9999.0   3.863499   1.254731    6.722111   3.544610  0.085925   6.070108   \n",
              "501 -9999.0  12.138727   1.450839   20.761660   3.565510  0.077548  17.801393   \n",
              "518 -9999.0   3.536205   1.433258    5.037868   3.277650  0.088665   5.492969   \n",
              "524 -9999.0  11.705633   7.285355    3.812838   2.824575  0.001829  24.173951   \n",
              "553 -9999.0   4.580298   1.511072    8.336963   3.000720  0.060600   6.891173   \n",
              "576 -9999.0   4.746960   0.997956   15.593540   2.885570  0.056971   7.349228   \n",
              "583 -9999.0   3.438417   0.839520    9.140577   3.359410  0.099237   5.456160   \n",
              "624 -9999.0   3.756250   1.089930    8.028431   3.398550  0.107655   5.249783   \n",
              "626 -9999.0   5.466269   1.044190   16.415246   3.046780  0.048442   7.804992   \n",
              "631 -9999.0   3.322417   1.355895    5.447101   3.224120  0.085435   5.262363   \n",
              "671 -9999.0   8.629715   2.425867    8.965462   3.450520  0.064947  20.285101   \n",
              "749 -9999.0   4.733237   1.521456    7.101676   3.233030  0.068319   7.195671   \n",
              "755 -9999.0   5.486405   1.277088   12.944733   2.826070  0.054069   7.810627   \n",
              "803 -9999.0   0.000061 -77.900491  434.978330   4.091920  0.084651   0.026476   \n",
              "817 -9999.0   2.757735   1.073076    7.633618   3.309370  0.104817   4.516250   \n",
              "844 -9999.0   3.090007   0.399857   31.030144   3.228790  0.089614   4.947239   \n",
              "846 -9999.0   2.790305   1.174401    6.318626   3.343790  0.106030   4.606572   \n",
              "892 -9999.0   7.231076   2.530636    7.117171   3.324940  0.091659  16.121489   \n",
              "894 -9999.0   3.102250   1.367696    5.106239   3.251950  0.092807   4.787800   \n",
              "903 -9999.0   5.794431   1.730441    7.783196   3.180180  0.060901   7.486296   \n",
              "912 -9999.0   3.601109   1.264992    5.158230   3.239030  0.101655   5.069206   \n",
              "\n",
              "     func_dvars  func_efc   func_fber  func_fwhm  func_gsr  func_mean_fd  \\\n",
              "6      1.107504  0.480033  111.161146   1.995363  0.025558      0.220653   \n",
              "8      1.178015  0.490547  101.314198   1.961812  0.036961      0.160136   \n",
              "64     1.143517  0.495382   80.000195   1.951576  0.030638      0.094722   \n",
              "86     1.317319  0.480779   86.052468   1.936867  0.026142      0.022373   \n",
              "98     1.127170  0.540687   84.153029   2.328669  0.027709      0.032230   \n",
              "147    1.138462  0.482650  104.150354   2.080765  0.035488      0.161788   \n",
              "159    1.163657  0.482051  124.373251   2.048877  0.022641      0.199617   \n",
              "224    1.216343  0.495054   88.843272   1.860183  0.030739      0.130655   \n",
              "225    1.035931  0.548127   78.684485   1.849910  0.046890      0.083783   \n",
              "326    1.097789  0.487604   79.486838   1.918145  0.042990      0.171107   \n",
              "341    1.190833  0.486656  109.718275   2.009262  0.041192      0.138318   \n",
              "452    1.049787  0.499136   77.083093   2.222115  0.029057      0.034014   \n",
              "497    1.145621  0.467642  118.887419   2.087152  0.026808      0.147701   \n",
              "501    0.852250  0.453736  114.796411   1.940677  0.031111      0.079033   \n",
              "518    1.142243  0.465977  124.576568   1.919242  0.030054      0.142374   \n",
              "524    0.999252  0.571828   53.651111   2.160952  0.046637      0.030265   \n",
              "553    1.179021  0.489111   92.033973   1.848336  0.037427      0.164435   \n",
              "576    1.153679  0.469991  124.681411   1.899898  0.017776      0.271007   \n",
              "583    1.204335  0.445782  205.468216   2.032735  0.019955      0.183134   \n",
              "624    1.188214  0.494691   91.066212   1.828907  0.020957      0.334374   \n",
              "626    1.197003  0.477982  114.541675   2.016993  0.020495      0.132729   \n",
              "631    1.158028  0.465215  115.298629   1.885277  0.020315      0.113176   \n",
              "671    1.013861  0.606909   51.904953   1.822706  0.058184      0.147098   \n",
              "749    1.116740  0.472449  116.536981   1.943543  0.021309      0.136413   \n",
              "755    1.114646  0.511716   82.045288   1.968684  0.034365      0.124083   \n",
              "803    1.080351  0.517160   76.632240   2.017880  0.038054      0.057301   \n",
              "817    1.122410  0.486408  108.510115   2.064103  0.033177      0.140171   \n",
              "844    1.082660  0.471565  103.960263   1.986581  0.022805      0.119588   \n",
              "846    1.055674  0.506452   60.808040   1.907286  0.029264      0.127575   \n",
              "892    0.985982  0.600982   61.296862   1.808763  0.055706      0.115698   \n",
              "894    1.152203  0.468724  122.397255   1.910385  0.025146      0.122904   \n",
              "903    1.110365  0.496913  130.969017   2.030166  0.034672      0.415470   \n",
              "912    1.192050  0.472395  104.648364   2.027010  0.038234      0.126411   \n",
              "\n",
              "     func_outlier  func_perc_fd  func_quality  \n",
              "6        0.000660     46.766169      0.005024  \n",
              "8        0.001758     30.845771      0.005715  \n",
              "64       0.001331      6.965174      0.004288  \n",
              "86       0.001375      0.000000      0.002551  \n",
              "98       0.001020      0.332226      0.007990  \n",
              "147      0.000728     26.865672      0.010123  \n",
              "159      0.000699     39.303483      0.006747  \n",
              "224      0.003248     14.925373      0.008621  \n",
              "225      0.007047      0.947867      0.009904  \n",
              "326      0.001749     33.830846      0.007724  \n",
              "341      0.000788     21.890547      0.006595  \n",
              "452      0.001631      0.000000      0.009963  \n",
              "497      0.001269     26.865672      0.004944  \n",
              "501      0.018740      3.317536      0.006492  \n",
              "518      0.001377     21.890547      0.005835  \n",
              "524      0.000898      0.332226      0.014246  \n",
              "553      0.000710     29.850746      0.006930  \n",
              "576      0.001424     71.641791      0.007928  \n",
              "583      0.003441     34.328358      0.009129  \n",
              "624      0.015621     31.840796      0.022776  \n",
              "626      0.001277     14.427861      0.005119  \n",
              "631      0.001143      9.452736      0.019403  \n",
              "671      0.000789     21.890547      0.019480  \n",
              "749      0.000944     22.388060      0.006209  \n",
              "755      0.001948     15.920398      0.007119  \n",
              "803      0.003345      3.973510      0.007524  \n",
              "817      0.001508     18.407960      0.012669  \n",
              "844      0.002412      9.950249      0.006920  \n",
              "846      0.001351     12.935323      0.008523  \n",
              "892      0.003953      9.452736      0.017076  \n",
              "894      0.000847     14.427861      0.005174  \n",
              "903      0.001460     75.621891      0.011393  \n",
              "912      0.002274     16.417910      0.006622  "
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outliers = df_float_missing[df_float_missing['FIQ'] == -9999]\n",
        "outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4CcK3fbH0Ki"
      },
      "source": [
        "We can see here, there are 33 rows where the FIQ values are equal to -9999, this is going to affect the MICE imputation strategy default which is mean, so for this reason, we will replace these values for NaN and include them in our missing values list in order to avoid being affected by these outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjhUpqZLMGfd"
      },
      "outputs": [],
      "source": [
        "df_float_missing['FIQ'] = df_float_missing['FIQ'].replace(-9999.0, np.NaN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdMXbnfmPO_o"
      },
      "outputs": [],
      "source": [
        "miss_val = df_float_missing.isna().any(axis = 1)\n",
        "val_null = df_float_missing[miss_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSlQ8FigWqF7",
        "outputId": "774a1bfb-64bc-4b25-c011-e3e8b2bfe7ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 16)"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_null.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y47PIWtXPTV"
      },
      "source": [
        "Here, we have the final dataset with missing values, now we will apply the Predictive Mean Matching data imputation method using the Multivariate Imputation via Chained Equations (MICE) based on the article process performed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWo3IaCR_fX6"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression() # The Predictive Mean Matching (PMM) uses Linear Regression in the MICE imputer as the estimator\n",
        "imp = IterativeImputer(estimator = lr, random_state=100, max_iter=10, imputation_order=\"roman\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3tN7xeK41KF"
      },
      "outputs": [],
      "source": [
        "imp_values = imp.fit_transform(df_float_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqBgRXIc9wLP"
      },
      "outputs": [],
      "source": [
        "df_float_missing.loc[:,:] = imp_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbE7yMZY-XO3",
        "outputId": "26f9f0e2-0ca0-4538-aff3-cc091c2b3555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "null = df_float_missing.isnull().sum()\n",
        "print(null[null > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0fPTdOWBSvU",
        "outputId": "18fe9e7b-7729-4237-e388-70e7548d3075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([119.        , 118.        , 142.        , 134.        ,\n",
              "       110.        , 107.02066371, 114.        , 109.82684071,\n",
              "       109.        ,  98.        , 131.        , 113.        ,\n",
              "       103.        ,  75.        , 108.77182052, 123.        ,\n",
              "       116.        ,  93.5       , 100.        , 113.5       ,\n",
              "       148.        , 104.        , 106.        ,  89.        ,\n",
              "        73.        ,  93.        , 101.        , 127.        ,\n",
              "       117.        , 126.        ,  97.        , 112.        ,\n",
              "       138.        , 136.        , 105.        , 120.        ,\n",
              "       111.5       , 111.        , 111.18733977, 102.        ,\n",
              "        86.        , 109.3729798 ,  76.        ,  91.        ,\n",
              "        69.6       , 115.        , 108.78829596, 122.        ,\n",
              "       106.5       , 110.21675352,  88.        , 110.89449895,\n",
              "       132.        , 129.        ,  83.        , 128.        ,\n",
              "       112.23338227,  98.5       , 108.        ,  95.5       ,\n",
              "       109.10403088, 141.        , 137.        , 109.97412205,\n",
              "       121.        , 121.5       ,  90.        ,  78.        ,\n",
              "        72.        , 107.        , 108.87489051, 125.        ,\n",
              "       105.23091445, 107.14797054, 109.50972366,  95.        ,\n",
              "       115.2       , 139.        , 107.6       ,  78.5       ,\n",
              "       103.5       ,  99.        ,  80.        , 124.        ,\n",
              "        92.        , 109.50497718, 109.37677231, 109.66004744,\n",
              "        94.        ,  96.        ,  77.        ,  92.5       ,\n",
              "        87.5       , 107.5       ,  79.        ,  85.        ,\n",
              "       135.        ,  87.        , 108.5       ,  96.5       ,\n",
              "       146.        , 130.        , 104.5       , 129.5       ,\n",
              "       124.5       , 110.5       , 108.47454113, 146.5       ,\n",
              "       109.7709114 , 112.5       , 115.5       , 110.71824964,\n",
              "        77.2       ,  89.5       ,  84.        , 127.5       ,\n",
              "       111.14977988, 133.5       , 112.16167925, 108.3749313 ,\n",
              "       120.5       , 105.7       ,  69.        , 112.76533491,\n",
              "       111.68265629, 112.18833505, 107.33578088, 105.63998941,\n",
              "       111.3435005 ,  97.5       , 109.24645248,  82.        ,\n",
              "       110.85304716, 110.63744778, 133.        , 114.5       ,\n",
              "        81.        , 111.81814031, 108.90225677, 140.        ,\n",
              "       106.68719738, 109.19240783, 118.5       , 104.93473946,\n",
              "       108.4239165 , 111.82599219, 110.7675841 , 118.7       ,\n",
              "       111.34331564, 123.5       ,  41.        , 110.35033671,\n",
              "       100.5       , 108.88824212, 144.        , 109.45052483,\n",
              "        99.5       , 108.83327683, 107.86017611, 112.21541605,\n",
              "       109.91099175, 109.48815825, 110.57707397, 108.19092348,\n",
              "       109.25843147, 109.65777666,  65.        , 147.5       ,\n",
              "       109.5       , 112.15690096, 109.91514932, 109.65809914,\n",
              "       104.34022583, 109.12001831, 125.5       ])"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_float_missing['FIQ'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIFGnqF2c9Me"
      },
      "outputs": [],
      "source": [
        "col = df_1.columns.difference(df_float_missing.columns)\n",
        "df_con = df_1[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnr1OnZvdOj9"
      },
      "outputs": [],
      "source": [
        "df_final = pd.concat([df_float_missing, df_con], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "l7xUjAfCfGaQ",
        "outputId": "743c7530-f6f6-4ef4-c598-c477342a2701"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-77a5b8e8-9ed3-42fc-9688-17d6c0659f1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "      <th>X</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>qc_anat_rater_2_fail</th>\n",
              "      <th>qc_anat_rater_2_maybe</th>\n",
              "      <th>qc_anat_rater_3_fail</th>\n",
              "      <th>qc_func_rater_2_fail</th>\n",
              "      <th>qc_func_rater_2_maybe</th>\n",
              "      <th>qc_func_rater_3_fail</th>\n",
              "      <th>qc_rater_1_fail</th>\n",
              "      <th>qc_rater_1_maybe</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.000000</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>815</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.000000</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.000000</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>864</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.000000</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>0</td>\n",
              "      <td>669</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.000000</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50653</td>\n",
              "      <td>0</td>\n",
              "      <td>509</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>110.000000</td>\n",
              "      <td>12.592915</td>\n",
              "      <td>2.854406</td>\n",
              "      <td>7.616887</td>\n",
              "      <td>3.282660</td>\n",
              "      <td>0.101390</td>\n",
              "      <td>25.763782</td>\n",
              "      <td>1.137542</td>\n",
              "      <td>0.565347</td>\n",
              "      <td>79.216368</td>\n",
              "      <td>1.871921</td>\n",
              "      <td>0.046415</td>\n",
              "      <td>0.039528</td>\n",
              "      <td>0.004377</td>\n",
              "      <td>0.497512</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>11.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51357</td>\n",
              "      <td>1</td>\n",
              "      <td>1026</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>107.020664</td>\n",
              "      <td>5.258132</td>\n",
              "      <td>1.436278</td>\n",
              "      <td>14.831974</td>\n",
              "      <td>2.911150</td>\n",
              "      <td>0.047992</td>\n",
              "      <td>8.450562</td>\n",
              "      <td>1.107504</td>\n",
              "      <td>0.480033</td>\n",
              "      <td>111.161146</td>\n",
              "      <td>1.995363</td>\n",
              "      <td>0.025558</td>\n",
              "      <td>0.220653</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>46.766169</td>\n",
              "      <td>0.005024</td>\n",
              "      <td>36.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51569</td>\n",
              "      <td>0</td>\n",
              "      <td>1094</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>8.071939</td>\n",
              "      <td>0.492807</td>\n",
              "      <td>90.430431</td>\n",
              "      <td>3.777362</td>\n",
              "      <td>0.061024</td>\n",
              "      <td>10.065393</td>\n",
              "      <td>0.935325</td>\n",
              "      <td>0.509945</td>\n",
              "      <td>111.912491</td>\n",
              "      <td>1.811479</td>\n",
              "      <td>-0.000797</td>\n",
              "      <td>0.045803</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>0.015515</td>\n",
              "      <td>26.1700</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51153</td>\n",
              "      <td>1</td>\n",
              "      <td>834</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>109.826841</td>\n",
              "      <td>2.940238</td>\n",
              "      <td>1.487330</td>\n",
              "      <td>2.540405</td>\n",
              "      <td>3.146340</td>\n",
              "      <td>0.130985</td>\n",
              "      <td>4.573468</td>\n",
              "      <td>1.178015</td>\n",
              "      <td>0.490547</td>\n",
              "      <td>101.314198</td>\n",
              "      <td>1.961812</td>\n",
              "      <td>0.036961</td>\n",
              "      <td>0.160136</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>30.845771</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>42.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51580</td>\n",
              "      <td>0</td>\n",
              "      <td>1105</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>109.000000</td>\n",
              "      <td>11.080846</td>\n",
              "      <td>0.416458</td>\n",
              "      <td>692.822630</td>\n",
              "      <td>3.090838</td>\n",
              "      <td>0.001943</td>\n",
              "      <td>22.997706</td>\n",
              "      <td>1.168608</td>\n",
              "      <td>0.514500</td>\n",
              "      <td>86.057649</td>\n",
              "      <td>2.492507</td>\n",
              "      <td>0.025435</td>\n",
              "      <td>0.245952</td>\n",
              "      <td>0.010103</td>\n",
              "      <td>44.518272</td>\n",
              "      <td>0.020060</td>\n",
              "      <td>11.8000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50316</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>134.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77a5b8e8-9ed3-42fc-9688-17d6c0659f1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77a5b8e8-9ed3-42fc-9688-17d6c0659f1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77a5b8e8-9ed3-42fc-9688-17d6c0659f1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          FIQ   anat_cnr   anat_efc   anat_fber  anat_fwhm  anat_qi1  \\\n",
              "0  119.000000  10.674176   0.616051   89.045514   3.509732  0.067764   \n",
              "1  118.000000   7.004004   1.674990   11.113986   4.425869  0.075520   \n",
              "2  119.000000   9.180373  14.838937    0.029120   2.824676  0.241977   \n",
              "3  142.000000   9.087565   0.517920   78.004528   3.220905  0.055056   \n",
              "4  134.000000  26.045369   4.167438   32.931736   3.423460  0.058810   \n",
              "5  110.000000  12.592915   2.854406    7.616887   3.282660  0.101390   \n",
              "6  107.020664   5.258132   1.436278   14.831974   2.911150  0.047992   \n",
              "7  114.000000   8.071939   0.492807   90.430431   3.777362  0.061024   \n",
              "8  109.826841   2.940238   1.487330    2.540405   3.146340  0.130985   \n",
              "9  109.000000  11.080846   0.416458  692.822630   3.090838  0.001943   \n",
              "\n",
              "    anat_snr  func_dvars  func_efc   func_fber  func_fwhm  func_gsr  \\\n",
              "0  12.866070    1.018414  0.534295   78.296410   1.765660 -0.001329   \n",
              "1  10.833468    1.064568  0.428382  137.815548   1.955725  0.010631   \n",
              "2   9.159445    1.302140  0.555808   59.038003   2.772167  0.036467   \n",
              "3  10.456115    0.938920  0.485962  142.036348   2.057008 -0.010039   \n",
              "4  68.951286    1.156320  0.585246   88.589366   1.680437  0.079297   \n",
              "5  25.763782    1.137542  0.565347   79.216368   1.871921  0.046415   \n",
              "6   8.450562    1.107504  0.480033  111.161146   1.995363  0.025558   \n",
              "7  10.065393    0.935325  0.509945  111.912491   1.811479 -0.000797   \n",
              "8   4.573468    1.178015  0.490547  101.314198   1.961812  0.036961   \n",
              "9  22.997706    1.168608  0.514500   86.057649   2.492507  0.025435   \n",
              "\n",
              "   func_mean_fd  func_outlier  func_perc_fd  func_quality  AGE_AT_SCAN  \\\n",
              "0      0.032827      0.006217      1.104972      0.014129      19.7300   \n",
              "1      0.078301      0.002349      4.635762      0.008713      21.4200   \n",
              "2      0.181608      0.007001     28.630705      0.007197       8.2464   \n",
              "3      0.030118      0.006253      0.552486      0.011202       9.5800   \n",
              "4      0.187709      0.001147     34.854772      0.007730      30.0000   \n",
              "5      0.039528      0.004377      0.497512      0.008172      11.0000   \n",
              "6      0.220653      0.000660     46.766169      0.005024      36.0000   \n",
              "7      0.045803      0.005884      1.104972      0.015515      26.1700   \n",
              "8      0.160136      0.001758     30.845771      0.005715      42.0000   \n",
              "9      0.245952      0.010103     44.518272      0.020060      11.8000   \n",
              "\n",
              "   DX_GROUP  EYE_STATUS_AT_SCAN  SEX  SUB_ID  SUB_IN_SMP     X  func_num_fd  \\\n",
              "0         2                   1    1   51131           1   815          2.0   \n",
              "1         1                   2    1   50237           1   163          7.0   \n",
              "2         2                   2    1   51185           1   864         69.0   \n",
              "3         1                   1    1   50978           0   669          1.0   \n",
              "4         1                   2    1   50653           0   509         84.0   \n",
              "5         2                   1    1   51357           1  1026          1.0   \n",
              "6         2                   2    1   51569           0  1094         94.0   \n",
              "7         2                   1    1   51153           1   834          2.0   \n",
              "8         1                   2    1   51580           0  1105         62.0   \n",
              "9         1                   1    1   50316           1   240        134.0   \n",
              "\n",
              "   qc_anat_rater_2_fail  qc_anat_rater_2_maybe  qc_anat_rater_3_fail  \\\n",
              "0                     0                      0                     0   \n",
              "1                     0                      0                     0   \n",
              "2                     0                      1                     0   \n",
              "3                     0                      0                     0   \n",
              "4                     0                      0                     0   \n",
              "5                     0                      1                     0   \n",
              "6                     0                      0                     0   \n",
              "7                     0                      0                     0   \n",
              "8                     0                      0                     0   \n",
              "9                     0                      1                     1   \n",
              "\n",
              "   qc_func_rater_2_fail  qc_func_rater_2_maybe  qc_func_rater_3_fail  \\\n",
              "0                     0                      0                     0   \n",
              "1                     0                      0                     0   \n",
              "2                     0                      0                     0   \n",
              "3                     0                      0                     0   \n",
              "4                     1                      0                     0   \n",
              "5                     0                      1                     0   \n",
              "6                     0                      1                     0   \n",
              "7                     0                      1                     0   \n",
              "8                     0                      1                     0   \n",
              "9                     0                      0                     0   \n",
              "\n",
              "   qc_rater_1_fail  qc_rater_1_maybe  subject  \n",
              "0                0                 0    51131  \n",
              "1                0                 0    50237  \n",
              "2                0                 0    51185  \n",
              "3                0                 0    50978  \n",
              "4                1                 0    50653  \n",
              "5                0                 0    51357  \n",
              "6                0                 0    51569  \n",
              "7                0                 0    51153  \n",
              "8                0                 0    51580  \n",
              "9                0                 0    50316  "
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b3EHfBYwPcn",
        "outputId": "d539388f-4be3-411a-f7e7-b0beaa24a72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "func_num_fd    1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "null2 = df_final.isnull().sum()\n",
        "print(null2[null2 > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY4mDDD5wTLr"
      },
      "outputs": [],
      "source": [
        "df_final['func_num_fd'] = df_final['func_num_fd'].fillna(df_final['func_num_fd'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGXX9aXlcUZh"
      },
      "source": [
        "### LDA process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H46pvWQXrx9u"
      },
      "source": [
        "The response variables of the article are the variables DX_GROUP and SEX, we do not have too much information about these variables in the dataset, so we will suppose that for alphabetic order the variables are distributed as follows:\n",
        "\n",
        "- DX_GROUP -> 1 = ASD, 2 = non-autistic (TD)\n",
        "- SEX -> 1 = Female, 2 = Male\n",
        "\n",
        "So, for the dataset we will replace the df_t colum for the target variable:\n",
        "\n",
        "- 0: ASD female (1_1)\n",
        "- 1: ASD male (1_2)\n",
        "- 2: non-autistic (TD) female (2_1)\n",
        "- 3: non_autistic (TD) male (2_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "FjO3COsJkppu",
        "outputId": "05d2f978-a5d0-4ae9-d8af-1910b3b62626"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3efcb92c-9aba-46e5-85a7-6fcd0b317062\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>DX_GROUP</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "      <th>X</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>qc_anat_rater_2_fail</th>\n",
              "      <th>qc_anat_rater_2_maybe</th>\n",
              "      <th>qc_anat_rater_3_fail</th>\n",
              "      <th>qc_func_rater_2_fail</th>\n",
              "      <th>qc_func_rater_2_maybe</th>\n",
              "      <th>qc_func_rater_3_fail</th>\n",
              "      <th>qc_rater_1_fail</th>\n",
              "      <th>qc_rater_1_maybe</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>815</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>864</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>0</td>\n",
              "      <td>669</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50653</td>\n",
              "      <td>0</td>\n",
              "      <td>509</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3efcb92c-9aba-46e5-85a7-6fcd0b317062')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3efcb92c-9aba-46e5-85a7-6fcd0b317062 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3efcb92c-9aba-46e5-85a7-6fcd0b317062');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     FIQ   anat_cnr   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \\\n",
              "0  119.0  10.674176   0.616051  89.045514   3.509732  0.067764  12.866070   \n",
              "1  118.0   7.004004   1.674990  11.113986   4.425869  0.075520  10.833468   \n",
              "2  119.0   9.180373  14.838937   0.029120   2.824676  0.241977   9.159445   \n",
              "3  142.0   9.087565   0.517920  78.004528   3.220905  0.055056  10.456115   \n",
              "4  134.0  26.045369   4.167438  32.931736   3.423460  0.058810  68.951286   \n",
              "\n",
              "   func_dvars  func_efc   func_fber  func_fwhm  func_gsr  func_mean_fd  \\\n",
              "0    1.018414  0.534295   78.296410   1.765660 -0.001329      0.032827   \n",
              "1    1.064568  0.428382  137.815548   1.955725  0.010631      0.078301   \n",
              "2    1.302140  0.555808   59.038003   2.772167  0.036467      0.181608   \n",
              "3    0.938920  0.485962  142.036348   2.057008 -0.010039      0.030118   \n",
              "4    1.156320  0.585246   88.589366   1.680437  0.079297      0.187709   \n",
              "\n",
              "   func_outlier  func_perc_fd  func_quality  AGE_AT_SCAN  DX_GROUP  \\\n",
              "0      0.006217      1.104972      0.014129      19.7300         2   \n",
              "1      0.002349      4.635762      0.008713      21.4200         1   \n",
              "2      0.007001     28.630705      0.007197       8.2464         2   \n",
              "3      0.006253      0.552486      0.011202       9.5800         1   \n",
              "4      0.001147     34.854772      0.007730      30.0000         1   \n",
              "\n",
              "   EYE_STATUS_AT_SCAN  SEX  SUB_ID  SUB_IN_SMP    X  func_num_fd  \\\n",
              "0                   1    1   51131           1  815          2.0   \n",
              "1                   2    1   50237           1  163          7.0   \n",
              "2                   2    1   51185           1  864         69.0   \n",
              "3                   1    1   50978           0  669          1.0   \n",
              "4                   2    1   50653           0  509         84.0   \n",
              "\n",
              "   qc_anat_rater_2_fail  qc_anat_rater_2_maybe  qc_anat_rater_3_fail  \\\n",
              "0                     0                      0                     0   \n",
              "1                     0                      0                     0   \n",
              "2                     0                      1                     0   \n",
              "3                     0                      0                     0   \n",
              "4                     0                      0                     0   \n",
              "\n",
              "   qc_func_rater_2_fail  qc_func_rater_2_maybe  qc_func_rater_3_fail  \\\n",
              "0                     0                      0                     0   \n",
              "1                     0                      0                     0   \n",
              "2                     0                      0                     0   \n",
              "3                     0                      0                     0   \n",
              "4                     1                      0                     0   \n",
              "\n",
              "   qc_rater_1_fail  qc_rater_1_maybe  subject  \n",
              "0                0                 0    51131  \n",
              "1                0                 0    50237  \n",
              "2                0                 0    51185  \n",
              "3                0                 0    50978  \n",
              "4                1                 0    50653  "
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-HgSqDPrTUs"
      },
      "outputs": [],
      "source": [
        "# Creating the target variable for the 4 groups:\n",
        "df_final['df_t'] = df_final['DX_GROUP'].astype(str) + '_' + df_final['SEX'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMKsymJSimmX",
        "outputId": "78ee9fb2-4736-452d-8688-81c6aa65850c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      2_1\n",
              "1      1_1\n",
              "2      2_1\n",
              "3      1_1\n",
              "4      1_1\n",
              "      ... \n",
              "926    2_2\n",
              "927    1_2\n",
              "928    1_1\n",
              "929    1_1\n",
              "930    2_1\n",
              "Name: df_t, Length: 931, dtype: object"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final['df_t']# we can see the groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcl8sNHSsQ0l"
      },
      "outputs": [],
      "source": [
        "df_final['target'] = df_final['df_t'].map({'1_1':0, '1_2':1, '2_1':2, '2_2':3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ8IdFmyjPMM",
        "outputId": "917577b5-905a-4be8-e7af-d101cb753a18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      2\n",
              "1      0\n",
              "2      2\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "926    3\n",
              "927    1\n",
              "928    0\n",
              "929    0\n",
              "930    2\n",
              "Name: target, Length: 931, dtype: int64"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final['target']# The final groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zLcRnwntWl4"
      },
      "outputs": [],
      "source": [
        "df_final = df_final.drop(['df_t', 'DX_GROUP', 'SEX'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "DIoJsDKWtdwi",
        "outputId": "88eb7770-8d27-4bae-a48a-4154f8210223"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-173b887b-18ef-4bfe-971c-3c65e60cb867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIQ</th>\n",
              "      <th>anat_cnr</th>\n",
              "      <th>anat_efc</th>\n",
              "      <th>anat_fber</th>\n",
              "      <th>anat_fwhm</th>\n",
              "      <th>anat_qi1</th>\n",
              "      <th>anat_snr</th>\n",
              "      <th>func_dvars</th>\n",
              "      <th>func_efc</th>\n",
              "      <th>func_fber</th>\n",
              "      <th>func_fwhm</th>\n",
              "      <th>func_gsr</th>\n",
              "      <th>func_mean_fd</th>\n",
              "      <th>func_outlier</th>\n",
              "      <th>func_perc_fd</th>\n",
              "      <th>func_quality</th>\n",
              "      <th>AGE_AT_SCAN</th>\n",
              "      <th>EYE_STATUS_AT_SCAN</th>\n",
              "      <th>SUB_ID</th>\n",
              "      <th>SUB_IN_SMP</th>\n",
              "      <th>X</th>\n",
              "      <th>func_num_fd</th>\n",
              "      <th>qc_anat_rater_2_fail</th>\n",
              "      <th>qc_anat_rater_2_maybe</th>\n",
              "      <th>qc_anat_rater_3_fail</th>\n",
              "      <th>qc_func_rater_2_fail</th>\n",
              "      <th>qc_func_rater_2_maybe</th>\n",
              "      <th>qc_func_rater_3_fail</th>\n",
              "      <th>qc_rater_1_fail</th>\n",
              "      <th>qc_rater_1_maybe</th>\n",
              "      <th>subject</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.0</td>\n",
              "      <td>10.674176</td>\n",
              "      <td>0.616051</td>\n",
              "      <td>89.045514</td>\n",
              "      <td>3.509732</td>\n",
              "      <td>0.067764</td>\n",
              "      <td>12.866070</td>\n",
              "      <td>1.018414</td>\n",
              "      <td>0.534295</td>\n",
              "      <td>78.296410</td>\n",
              "      <td>1.765660</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>1.104972</td>\n",
              "      <td>0.014129</td>\n",
              "      <td>19.7300</td>\n",
              "      <td>1</td>\n",
              "      <td>51131</td>\n",
              "      <td>1</td>\n",
              "      <td>815</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51131</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118.0</td>\n",
              "      <td>7.004004</td>\n",
              "      <td>1.674990</td>\n",
              "      <td>11.113986</td>\n",
              "      <td>4.425869</td>\n",
              "      <td>0.075520</td>\n",
              "      <td>10.833468</td>\n",
              "      <td>1.064568</td>\n",
              "      <td>0.428382</td>\n",
              "      <td>137.815548</td>\n",
              "      <td>1.955725</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.078301</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>4.635762</td>\n",
              "      <td>0.008713</td>\n",
              "      <td>21.4200</td>\n",
              "      <td>2</td>\n",
              "      <td>50237</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50237</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.0</td>\n",
              "      <td>9.180373</td>\n",
              "      <td>14.838937</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>2.824676</td>\n",
              "      <td>0.241977</td>\n",
              "      <td>9.159445</td>\n",
              "      <td>1.302140</td>\n",
              "      <td>0.555808</td>\n",
              "      <td>59.038003</td>\n",
              "      <td>2.772167</td>\n",
              "      <td>0.036467</td>\n",
              "      <td>0.181608</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>28.630705</td>\n",
              "      <td>0.007197</td>\n",
              "      <td>8.2464</td>\n",
              "      <td>2</td>\n",
              "      <td>51185</td>\n",
              "      <td>1</td>\n",
              "      <td>864</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51185</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>142.0</td>\n",
              "      <td>9.087565</td>\n",
              "      <td>0.517920</td>\n",
              "      <td>78.004528</td>\n",
              "      <td>3.220905</td>\n",
              "      <td>0.055056</td>\n",
              "      <td>10.456115</td>\n",
              "      <td>0.938920</td>\n",
              "      <td>0.485962</td>\n",
              "      <td>142.036348</td>\n",
              "      <td>2.057008</td>\n",
              "      <td>-0.010039</td>\n",
              "      <td>0.030118</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.552486</td>\n",
              "      <td>0.011202</td>\n",
              "      <td>9.5800</td>\n",
              "      <td>1</td>\n",
              "      <td>50978</td>\n",
              "      <td>0</td>\n",
              "      <td>669</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50978</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>26.045369</td>\n",
              "      <td>4.167438</td>\n",
              "      <td>32.931736</td>\n",
              "      <td>3.423460</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>68.951286</td>\n",
              "      <td>1.156320</td>\n",
              "      <td>0.585246</td>\n",
              "      <td>88.589366</td>\n",
              "      <td>1.680437</td>\n",
              "      <td>0.079297</td>\n",
              "      <td>0.187709</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>34.854772</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>50653</td>\n",
              "      <td>0</td>\n",
              "      <td>509</td>\n",
              "      <td>84.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50653</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173b887b-18ef-4bfe-971c-3c65e60cb867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-173b887b-18ef-4bfe-971c-3c65e60cb867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-173b887b-18ef-4bfe-971c-3c65e60cb867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     FIQ   anat_cnr   anat_efc  anat_fber  anat_fwhm  anat_qi1   anat_snr  \\\n",
              "0  119.0  10.674176   0.616051  89.045514   3.509732  0.067764  12.866070   \n",
              "1  118.0   7.004004   1.674990  11.113986   4.425869  0.075520  10.833468   \n",
              "2  119.0   9.180373  14.838937   0.029120   2.824676  0.241977   9.159445   \n",
              "3  142.0   9.087565   0.517920  78.004528   3.220905  0.055056  10.456115   \n",
              "4  134.0  26.045369   4.167438  32.931736   3.423460  0.058810  68.951286   \n",
              "\n",
              "   func_dvars  func_efc   func_fber  func_fwhm  func_gsr  func_mean_fd  \\\n",
              "0    1.018414  0.534295   78.296410   1.765660 -0.001329      0.032827   \n",
              "1    1.064568  0.428382  137.815548   1.955725  0.010631      0.078301   \n",
              "2    1.302140  0.555808   59.038003   2.772167  0.036467      0.181608   \n",
              "3    0.938920  0.485962  142.036348   2.057008 -0.010039      0.030118   \n",
              "4    1.156320  0.585246   88.589366   1.680437  0.079297      0.187709   \n",
              "\n",
              "   func_outlier  func_perc_fd  func_quality  AGE_AT_SCAN  EYE_STATUS_AT_SCAN  \\\n",
              "0      0.006217      1.104972      0.014129      19.7300                   1   \n",
              "1      0.002349      4.635762      0.008713      21.4200                   2   \n",
              "2      0.007001     28.630705      0.007197       8.2464                   2   \n",
              "3      0.006253      0.552486      0.011202       9.5800                   1   \n",
              "4      0.001147     34.854772      0.007730      30.0000                   2   \n",
              "\n",
              "   SUB_ID  SUB_IN_SMP    X  func_num_fd  qc_anat_rater_2_fail  \\\n",
              "0   51131           1  815          2.0                     0   \n",
              "1   50237           1  163          7.0                     0   \n",
              "2   51185           1  864         69.0                     0   \n",
              "3   50978           0  669          1.0                     0   \n",
              "4   50653           0  509         84.0                     0   \n",
              "\n",
              "   qc_anat_rater_2_maybe  qc_anat_rater_3_fail  qc_func_rater_2_fail  \\\n",
              "0                      0                     0                     0   \n",
              "1                      0                     0                     0   \n",
              "2                      1                     0                     0   \n",
              "3                      0                     0                     0   \n",
              "4                      0                     0                     1   \n",
              "\n",
              "   qc_func_rater_2_maybe  qc_func_rater_3_fail  qc_rater_1_fail  \\\n",
              "0                      0                     0                0   \n",
              "1                      0                     0                0   \n",
              "2                      0                     0                0   \n",
              "3                      0                     0                0   \n",
              "4                      0                     0                1   \n",
              "\n",
              "   qc_rater_1_maybe  subject  target  \n",
              "0                 0    51131       2  \n",
              "1                 0    50237       0  \n",
              "2                 0    51185       2  \n",
              "3                 0    50978       0  \n",
              "4                 0    50653       0  "
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFniGGo4lnBk"
      },
      "outputs": [],
      "source": [
        "# CREATING THE MODEL:\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8yuUeJEldSl"
      },
      "outputs": [],
      "source": [
        "X = df_final.drop(['target'], axis=1)\n",
        "y = df_final[['target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E03I8QyfrMX"
      },
      "outputs": [],
      "source": [
        "# Scaling the data:\n",
        "sc = StandardScaler()\n",
        "\n",
        "#Fit and tranform the data\n",
        "X_scl = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU2W8ycwpatr"
      },
      "outputs": [],
      "source": [
        "# The article mentions 75% of the data was use for training, 25% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scl, y, test_size = 0.25, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heYlZK_Yp4_q"
      },
      "outputs": [],
      "source": [
        "lda = LDA()\n",
        "lda_model = lda.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJCCfCL2uAJ2",
        "outputId": "dfe399a7-6824-41af-ae65-a559bf9e6269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.83998613, 0.11353641, 0.04647746])"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_model.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptYq_PIfuFpf"
      },
      "source": [
        "We found similar Discriminant axes that explain the the variance. LDA1= 84%, LDA2= 11.35%, LDA3 = 4.65%. Our results our similar to the results of the article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2V72J5nqcP3"
      },
      "outputs": [],
      "source": [
        "y_pred = lda_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td1t5Obg0azS",
        "outputId": "57b9604d-b110-45b2-925c-15b6f65ffc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy 0.6008583690987125\n"
          ]
        }
      ],
      "source": [
        "accuracy_score = lda_model.score(X_test, y_test)\n",
        "print('Model accuracy {0}'.format(accuracy_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYOk39_81R3F",
        "outputId": "57c6ebe5-4853-4857-f8e2-785d4cc4f65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.60      0.59        88\n",
            "           1       0.33      0.12      0.17        17\n",
            "           2       0.66      0.60      0.63       101\n",
            "           3       0.56      0.89      0.69        27\n",
            "\n",
            "    accuracy                           0.60       233\n",
            "   macro avg       0.53      0.55      0.52       233\n",
            "weighted avg       0.59      0.60      0.59       233\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluationg the model performance using classification report (precision, recall, f1-score)\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "i6opoUSem2Q1",
        "outputId": "52dbac56-660c-412b-b843-25c9e6a6ddd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 294,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Predicting the Test set results\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7_FPfTv3K62"
      },
      "outputs": [],
      "source": [
        "# Testing the model including Cross Validation with 10 times repetitions\n",
        "k = KFold(n_splits = 10, random_state = 1, shuffle = True)\n",
        "cv_scores = cross_val_score(lda_model, X_train, y_train, cv = k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr3nZ0n75bk_",
        "outputId": "2286301f-9e47-4c5e-e2d7-2e089ba3050d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy 0.5660041407867495\n"
          ]
        }
      ],
      "source": [
        "# Cross Validation accuracy\n",
        "print('Model accuracy {0}'.format(cv_scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T4zVHvhc97n",
        "outputId": "a665229c-8a15-4886-b431-f7cee54a8adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASD female\n",
            "Sensitivity: 0.6022727272727273\n",
            "Specificity: 0.7379310344827587\n",
            "\n",
            "ASD male\n",
            "Sensitivity: 0.11764705882352941\n",
            "Specificity: 0.9814814814814815\n",
            "\n",
            "non-autistic female\n",
            "Sensitivity: 0.6039603960396039\n",
            "Specificity: 0.7575757575757576\n",
            "\n",
            "non-autistic male\n",
            "Sensitivity: 0.8888888888888888\n",
            "Specificity: 0.9077669902912622\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Sensitivity and Specificity of our model\n",
        "# Define the group mappings\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "group_mapping = {\n",
        "    0: 'ASD female',\n",
        "    1: 'ASD male',\n",
        "    2: 'non-autistic female',\n",
        "    3: 'non-autistic male'\n",
        "}\n",
        "\n",
        "# Calculate confusion matrix for each group\n",
        "group_confusion_matrices = {}\n",
        "for group_code, group_name in group_mapping.items():\n",
        "    group_y_test = (y_test == group_code)\n",
        "    group_y_pred = (y_pred == group_code)\n",
        "    group_confusion_matrices[group_name] = confusion_matrix(group_y_test, group_y_pred)\n",
        "\n",
        "# Calculate sensitivity and specificity for each group\n",
        "group_metrics = {}\n",
        "for group_name, confusion_matrix in group_confusion_matrices.items():\n",
        "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    group_metrics[group_name] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
        "\n",
        "# Print the results for each group\n",
        "for group_name, metrics in group_metrics.items():\n",
        "    print(group_name)\n",
        "    print(\"Sensitivity:\", metrics['sensitivity'])\n",
        "    print(\"Specificity:\", metrics['specificity'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw0xnUCpmFm2"
      },
      "source": [
        "### Model's Conclusion and its comparison vs the article's conclusion:\n",
        "\n",
        "The results of our model are:\n",
        "\n",
        "- Overall model accuracy: 60.085%\n",
        "- Model accuracy performing Cross Validation 10 times: 56.6%\n",
        "- Model Precision: ASD female (0) = 58%, ASD male (1) = 33%, TD female (2) = 66%, TD male (3) = 56%\n",
        "- Model Recall: ASD female (0) = 60%, ASD male (1) = 12%, TD female (2) = 60%, TD male (3) = 89%\n",
        "- Model F1 - score: ASD female (0) = 59%, ASD male (1) = 17%, TD female (2) = 63%, TD male (3) = 69%\n",
        "\n",
        "Comparting our models results vs the article results we have:\n",
        "\n",
        "- Our model result without performing the cross-validation is 60.08% which means the performance of the model is close to the article model's performance result (62.77%).\n",
        "- Our model result performing the cross-validation is 56.6%, this result is a little bit lower than the article model's performance, but still, it is considered a moderate accuracy.\n",
        "- Model Precision: The article model's precision results are ASD female = 56%, ASD male = 70.37%, TD female = 64.29%, and TD male = 60.71%, here we can see that our Precision results are similar to the article model's Precision results, the only values with the highest difference are the ASD male results.\n",
        "- Model Balanced Accuracy: The article model's Balanced Accuracy results are ASD female = 72.69%, ASD male = 79.22%, TD female = 68%, and TD male = 79.21%, here we can see that our Recall results are lower than the article model's Balanced Accuracy results.\n",
        "- Model F1 - score: The article model's F1 - score are ASD female = 58.33%, ASD male = 70.37%, TD female = 51.43%, TD male = 66.67%, here we can see that our F1 - score results are similar to the article model's F1 - score results, the only values with the highest difference are the ASD male results.\n",
        "\n",
        "\n",
        "\n",
        "Now we are going to compare sensitivity and specificity of article's LDA vrs our model LDA.\n",
        "\n",
        "\n",
        "## Article's LDA Classification report\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Sensitivity | 60.87% | 70.37% | 42.86% | 73.91% |\n",
        "| Specificity | 84.51% | 88.06% | 93.15% | 84.51% |\n",
        "\n",
        "\n",
        "# Our LDA Classification report\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Sensitivity | 60.23% | 11.76% | 60.40% | 88.89% |\n",
        "| Specificity | 73.80% | 98.15% | 75.75% | 90.78% |\n",
        "\n",
        "Based on the results, it can be observed that the article's LDA model generally outperforms our replicated LDA model in terms of sensitivity for most groups. However, our replicated LDA model exhibits higher specificity for ASD males compared to the article's LDA model.This indicates that our replicated LDA model exhibits better performance in correctly identifying non-autistic (TD) males as non-autistic. It suggests that our model have the ability to correctly identify true negatives (non-autistic individuals) within that category.However,  model's ability to correctly identify true positives (autistic individuals) is not good and Sensitivity it is typically more important in the context of autism classification.\n",
        "\n",
        "Further analysis and improvements may be necessary to enhance the performance of our LDA model in order to match or exceed the results of the article's LDA model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoDM6K2plQc5"
      },
      "source": [
        "## 3. Perform another classification analysis (15 points).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJJrNRU8WF9x"
      },
      "source": [
        "Using Random Forest Classifiers as another Classification Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0yP1HYq5Gtw"
      },
      "outputs": [],
      "source": [
        "# First, we are going to look for the best parameters\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "forest_param= {'max_depth': list(range(10,15)),\n",
        "               'max_features': list(range(0,14)),\n",
        "               'n_estimators':[10,25,50,75,100]}\n",
        "grid_search = GridSearchCV(estimator = rfc,\n",
        "                           param_grid = forest_param,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           verbose=0)\n",
        "\n",
        "\n",
        "result = grid_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqvjvvK86UZq",
        "outputId": "7629361f-af3a-41d1-d7c6-19476fdb99a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Score: 0.763699614743258\n",
            "Best Hyperparameters: {'max_depth': 14, 'max_features': 8, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz-JW3G4WUrj"
      },
      "source": [
        "Using the best parameteres in our Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxY0gPFRPjis"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=100, max_depth=14,max_features=8, random_state=0)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "y_pred=rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0zuSqQMPwoa",
        "outputId": "0e045698-f0b3-4d55-e530-a59c74f07563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7296137339055794\n"
          ]
        }
      ],
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P69A8Rm9P6Tn",
        "outputId": "37df5cd4-d9b7-42e9-86cb-9b4ca61e20eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.88      0.76        88\n",
            "           1       0.50      0.18      0.26        17\n",
            "           2       0.84      0.71      0.77       101\n",
            "           3       0.69      0.67      0.68        27\n",
            "\n",
            "    accuracy                           0.73       233\n",
            "   macro avg       0.67      0.61      0.62       233\n",
            "weighted avg       0.73      0.73      0.72       233\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EggpvxiIQC4l"
      },
      "outputs": [],
      "source": [
        "# Testing the model including Cross Validation with 10 times repetitions\n",
        "k = KFold(n_splits = 10, random_state = 0, shuffle = True)\n",
        "cv_scores = cross_val_score(rfc, X_train, y_train, cv = k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVV1OAGpQJ70",
        "outputId": "a25d8e68-aae0-4c4c-e558-e00e8d9bb292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy 0.7378260869565217\n"
          ]
        }
      ],
      "source": [
        "# Cross Validation accuracy\n",
        "print('Model accuracy {0}'.format(cv_scores.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne3fYXhMRrSU",
        "outputId": "1bf81a3f-6c5d-4df8-a335-bad895b31361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASD female\n",
            "Sensitivity: 0.875\n",
            "Specificity: 0.7379310344827587\n",
            "\n",
            "ASD male\n",
            "Sensitivity: 0.17647058823529413\n",
            "Specificity: 0.9861111111111112\n",
            "\n",
            "non-autistic female\n",
            "Sensitivity: 0.7128712871287128\n",
            "Specificity: 0.8939393939393939\n",
            "\n",
            "non-autistic male\n",
            "Sensitivity: 0.6666666666666666\n",
            "Specificity: 0.9611650485436893\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Sensitivity and Specificity of our model\n",
        "# Define the group mappings\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "group_mapping = {\n",
        "    0: 'ASD female',\n",
        "    1: 'ASD male',\n",
        "    2: 'non-autistic female',\n",
        "    3: 'non-autistic male'\n",
        "}\n",
        "\n",
        "# Calculate confusion matrix for each group\n",
        "group_confusion_matrices = {}\n",
        "for group_code, group_name in group_mapping.items():\n",
        "    group_y_test = (y_test == group_code)\n",
        "    group_y_pred = (y_pred == group_code)\n",
        "    group_confusion_matrices[group_name] = confusion_matrix(group_y_test, group_y_pred)\n",
        "\n",
        "# Calculate sensitivity and specificity for each group\n",
        "group_metrics = {}\n",
        "for group_name, confusion_matrix in group_confusion_matrices.items():\n",
        "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    group_metrics[group_name] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
        "\n",
        "# Print the results for each group\n",
        "for group_name, metrics in group_metrics.items():\n",
        "    print(group_name)\n",
        "    print(\"Sensitivity:\", metrics['sensitivity'])\n",
        "    print(\"Specificity:\", metrics['specificity'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG9hx8gJl-no"
      },
      "source": [
        "## 4.Conclusion on the performance of LDA in comparison to the technique that you use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmpbGwRjCgPR"
      },
      "source": [
        "### Model's Conclusion and its comparison Random Forest Classifiers  vs LDA model:\n",
        "\n",
        "The results of  Random Forest Classifiers are:\n",
        "\n",
        "- Overall model accuracy: 73%\n",
        "- Model accuracy performing Cross Validation 10 times: 73.8%\n",
        "- Model Precision: ASD female (0) = 67%, ASD male (1) = 50%, TD female (2) = 84%, TD male (3) = 69%\n",
        "- Model Recall: ASD female (0) = 88%, ASD male (1) = 18%, TD female (2) = 71%, TD male (3) = 67%\n",
        "- Model F1 - score: ASD female (0) = 76%, ASD male (1) = 26%, TD female (2) = 77%, TD male (3) = 68%\n",
        "\n",
        "Comparting our models results vs the LDA results we have:\n",
        "\n",
        "- Our model result without performing the cross-validation is 72.96% which means the performance of the model is better to the article model's performance result (62.77%) and better of our LDA performance(60.08%)\n",
        "- Our model result performing the cross-validation is 73.78%, this result is better  than the article model's performance and better than our LDA (56.6%)\n",
        "\n",
        "Compare precision with LDA and Random\n",
        "\n",
        "\n",
        "- Model Precision: The article model's precision results are ASD female = 56%, ASD male = 70.37%, TD female = 64.29%, and TD male = 60.71%, here we can see that our Precision results are similar to the article model's Precision results, the only values with the highest difference are the ASD male results.\n",
        "- Model Balanced Accuracy: The article model's Balanced Accuracy results are ASD female = 72.69%, ASD male = 79.22%, TD female = 68%, and TD male = 79.21%, here we can see that our Recall results are lower than the article model's Balanced Accuracy results.\n",
        "- Model F1 - score: The article model's F1 - score are ASD female = 58.33%, ASD male = 70.37%, TD female = 51.43%, TD male = 66.67%, here we can see that our F1 - score results are similar to the article model's F1 - score results, the only values with the highest difference are the ASD male results.\n",
        "\n",
        "## LDA\n",
        "\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Precision | 58% | 33% | 66% | 56% |\n",
        "| Recall | 60% | 12% | 60% | 89% |\n",
        "| f1-score | 59% | 17% | 63% | 69% |\n",
        "\n",
        "\n",
        "\n",
        "# Random Forest Classifier\n",
        "\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Precision | 67% | 50% | 84% | 69% |\n",
        "| Recall | 88% | 18% | 71% | 67% |\n",
        "| f1-score | 76% | 26% | 77% | 68% |\n",
        "\n",
        "\n",
        "As we can easily see the Random Forest Clasiffier provide higher Accuracy and also better classification statistics. We have to remember that always there is a threshold between bias and variance. So we can have a higher precision and we can have a low Recall. It is always depende of our dataset.\n",
        "\n",
        "To improve our model, we utilized the optimized parameter settings and applied the Random Forest algorithm. By employing these higher-tuned parameters, we aimed to enhance the performance and accuracy of our model. Random Forest is a powerful ensemble learning technique that combines multiple decision trees to make robust predictions. This approach allows for improved generalization and can effectively handle complex data patterns.\n",
        "\n",
        "Now we are going to compare sensitivity and specificity LDA vrs Random Forest Classifiers.\n",
        "\n",
        "# Our LDA Classification report\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Sensitivity | 60.23% | 11.76% | 60.40% | 88.89% |\n",
        "| Specificity | 73.80% | 98.15% | 75.75% | 90.78% |\n",
        "\n",
        "\n",
        "\n",
        "## Random Forest Classification report\n",
        "\n",
        "| Indicator | ASD female | ASD male | TD female | TD male |\n",
        "|---|---|---|---|---|\n",
        "| Sensitivity | 87.50% | 17.65% | 71.28% | 66.67% |\n",
        "| Specificity | 73.80% | 98.61% | 89.39% | 96.12% |\n",
        "\n",
        "\n",
        "Overall, the Random Forest model outperformed our LDA model in terms of sensitivity for most groups, except for TD males. The Random Forest model also showed higher specificity for most groups compared to our LDA model. These results indicate that the Random Forest model generally performs better in accurately identifying positive cases (sensitivity) and negative cases (specificity) within the different groups of ASD and non-autistic individuals.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn0fMd1jWzJu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}